{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection using Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import of Libaries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>9.481386e+04</td>\n",
       "      <td>47488.145955</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54201.500000</td>\n",
       "      <td>84692.000000</td>\n",
       "      <td>139320.500000</td>\n",
       "      <td>172792.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>3.919560e-15</td>\n",
       "      <td>1.958696</td>\n",
       "      <td>-56.407510</td>\n",
       "      <td>-0.920373</td>\n",
       "      <td>0.018109</td>\n",
       "      <td>1.315642</td>\n",
       "      <td>2.454930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V2</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>5.688174e-16</td>\n",
       "      <td>1.651309</td>\n",
       "      <td>-72.715728</td>\n",
       "      <td>-0.598550</td>\n",
       "      <td>0.065486</td>\n",
       "      <td>0.803724</td>\n",
       "      <td>22.057729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V3</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-8.769071e-15</td>\n",
       "      <td>1.516255</td>\n",
       "      <td>-48.325589</td>\n",
       "      <td>-0.890365</td>\n",
       "      <td>0.179846</td>\n",
       "      <td>1.027196</td>\n",
       "      <td>9.382558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V4</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>2.782312e-15</td>\n",
       "      <td>1.415869</td>\n",
       "      <td>-5.683171</td>\n",
       "      <td>-0.848640</td>\n",
       "      <td>-0.019847</td>\n",
       "      <td>0.743341</td>\n",
       "      <td>16.875344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V5</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-1.552563e-15</td>\n",
       "      <td>1.380247</td>\n",
       "      <td>-113.743307</td>\n",
       "      <td>-0.691597</td>\n",
       "      <td>-0.054336</td>\n",
       "      <td>0.611926</td>\n",
       "      <td>34.801666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V6</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>2.010663e-15</td>\n",
       "      <td>1.332271</td>\n",
       "      <td>-26.160506</td>\n",
       "      <td>-0.768296</td>\n",
       "      <td>-0.274187</td>\n",
       "      <td>0.398565</td>\n",
       "      <td>73.301626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V7</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-1.694249e-15</td>\n",
       "      <td>1.237094</td>\n",
       "      <td>-43.557242</td>\n",
       "      <td>-0.554076</td>\n",
       "      <td>0.040103</td>\n",
       "      <td>0.570436</td>\n",
       "      <td>120.589494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V8</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-1.927028e-16</td>\n",
       "      <td>1.194353</td>\n",
       "      <td>-73.216718</td>\n",
       "      <td>-0.208630</td>\n",
       "      <td>0.022358</td>\n",
       "      <td>0.327346</td>\n",
       "      <td>20.007208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V9</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-3.137024e-15</td>\n",
       "      <td>1.098632</td>\n",
       "      <td>-13.434066</td>\n",
       "      <td>-0.643098</td>\n",
       "      <td>-0.051429</td>\n",
       "      <td>0.597139</td>\n",
       "      <td>15.594995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V10</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.768627e-15</td>\n",
       "      <td>1.088850</td>\n",
       "      <td>-24.588262</td>\n",
       "      <td>-0.535426</td>\n",
       "      <td>-0.092917</td>\n",
       "      <td>0.453923</td>\n",
       "      <td>23.745136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V11</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>9.170318e-16</td>\n",
       "      <td>1.020713</td>\n",
       "      <td>-4.797473</td>\n",
       "      <td>-0.762494</td>\n",
       "      <td>-0.032757</td>\n",
       "      <td>0.739593</td>\n",
       "      <td>12.018913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V12</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-1.810658e-15</td>\n",
       "      <td>0.999201</td>\n",
       "      <td>-18.683715</td>\n",
       "      <td>-0.405571</td>\n",
       "      <td>0.140033</td>\n",
       "      <td>0.618238</td>\n",
       "      <td>7.848392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V13</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.693438e-15</td>\n",
       "      <td>0.995274</td>\n",
       "      <td>-5.791881</td>\n",
       "      <td>-0.648539</td>\n",
       "      <td>-0.013568</td>\n",
       "      <td>0.662505</td>\n",
       "      <td>7.126883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V14</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.479045e-15</td>\n",
       "      <td>0.958596</td>\n",
       "      <td>-19.214325</td>\n",
       "      <td>-0.425574</td>\n",
       "      <td>0.050601</td>\n",
       "      <td>0.493150</td>\n",
       "      <td>10.526766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V15</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>3.482336e-15</td>\n",
       "      <td>0.915316</td>\n",
       "      <td>-4.498945</td>\n",
       "      <td>-0.582884</td>\n",
       "      <td>0.048072</td>\n",
       "      <td>0.648821</td>\n",
       "      <td>8.877742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V16</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.392007e-15</td>\n",
       "      <td>0.876253</td>\n",
       "      <td>-14.129855</td>\n",
       "      <td>-0.468037</td>\n",
       "      <td>0.066413</td>\n",
       "      <td>0.523296</td>\n",
       "      <td>17.315112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V17</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-7.528491e-16</td>\n",
       "      <td>0.849337</td>\n",
       "      <td>-25.162799</td>\n",
       "      <td>-0.483748</td>\n",
       "      <td>-0.065676</td>\n",
       "      <td>0.399675</td>\n",
       "      <td>9.253526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V18</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>4.328772e-16</td>\n",
       "      <td>0.838176</td>\n",
       "      <td>-9.498746</td>\n",
       "      <td>-0.498850</td>\n",
       "      <td>-0.003636</td>\n",
       "      <td>0.500807</td>\n",
       "      <td>5.041069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V19</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>9.049732e-16</td>\n",
       "      <td>0.814041</td>\n",
       "      <td>-7.213527</td>\n",
       "      <td>-0.456299</td>\n",
       "      <td>0.003735</td>\n",
       "      <td>0.458949</td>\n",
       "      <td>5.591971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V20</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>5.085503e-16</td>\n",
       "      <td>0.770925</td>\n",
       "      <td>-54.497720</td>\n",
       "      <td>-0.211721</td>\n",
       "      <td>-0.062481</td>\n",
       "      <td>0.133041</td>\n",
       "      <td>39.420904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V21</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.537294e-16</td>\n",
       "      <td>0.734524</td>\n",
       "      <td>-34.830382</td>\n",
       "      <td>-0.228395</td>\n",
       "      <td>-0.029450</td>\n",
       "      <td>0.186377</td>\n",
       "      <td>27.202839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V22</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>7.959909e-16</td>\n",
       "      <td>0.725702</td>\n",
       "      <td>-10.933144</td>\n",
       "      <td>-0.542350</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>0.528554</td>\n",
       "      <td>10.503090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V23</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>5.367590e-16</td>\n",
       "      <td>0.624460</td>\n",
       "      <td>-44.807735</td>\n",
       "      <td>-0.161846</td>\n",
       "      <td>-0.011193</td>\n",
       "      <td>0.147642</td>\n",
       "      <td>22.528412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V24</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>4.458112e-15</td>\n",
       "      <td>0.605647</td>\n",
       "      <td>-2.836627</td>\n",
       "      <td>-0.354586</td>\n",
       "      <td>0.040976</td>\n",
       "      <td>0.439527</td>\n",
       "      <td>4.584549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V25</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.453003e-15</td>\n",
       "      <td>0.521278</td>\n",
       "      <td>-10.295397</td>\n",
       "      <td>-0.317145</td>\n",
       "      <td>0.016594</td>\n",
       "      <td>0.350716</td>\n",
       "      <td>7.519589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V26</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.699104e-15</td>\n",
       "      <td>0.482227</td>\n",
       "      <td>-2.604551</td>\n",
       "      <td>-0.326984</td>\n",
       "      <td>-0.052139</td>\n",
       "      <td>0.240952</td>\n",
       "      <td>3.517346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V27</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-3.660161e-16</td>\n",
       "      <td>0.403632</td>\n",
       "      <td>-22.565679</td>\n",
       "      <td>-0.070840</td>\n",
       "      <td>0.001342</td>\n",
       "      <td>0.091045</td>\n",
       "      <td>31.612198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V28</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-1.206049e-16</td>\n",
       "      <td>0.330083</td>\n",
       "      <td>-15.430084</td>\n",
       "      <td>-0.052960</td>\n",
       "      <td>0.011244</td>\n",
       "      <td>0.078280</td>\n",
       "      <td>33.847808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amount</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>8.834962e+01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>25691.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.727486e-03</td>\n",
       "      <td>0.041527</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count          mean           std         min           25%  \\\n",
       "Time    284807.0  9.481386e+04  47488.145955    0.000000  54201.500000   \n",
       "V1      284807.0  3.919560e-15      1.958696  -56.407510     -0.920373   \n",
       "V2      284807.0  5.688174e-16      1.651309  -72.715728     -0.598550   \n",
       "V3      284807.0 -8.769071e-15      1.516255  -48.325589     -0.890365   \n",
       "V4      284807.0  2.782312e-15      1.415869   -5.683171     -0.848640   \n",
       "V5      284807.0 -1.552563e-15      1.380247 -113.743307     -0.691597   \n",
       "V6      284807.0  2.010663e-15      1.332271  -26.160506     -0.768296   \n",
       "V7      284807.0 -1.694249e-15      1.237094  -43.557242     -0.554076   \n",
       "V8      284807.0 -1.927028e-16      1.194353  -73.216718     -0.208630   \n",
       "V9      284807.0 -3.137024e-15      1.098632  -13.434066     -0.643098   \n",
       "V10     284807.0  1.768627e-15      1.088850  -24.588262     -0.535426   \n",
       "V11     284807.0  9.170318e-16      1.020713   -4.797473     -0.762494   \n",
       "V12     284807.0 -1.810658e-15      0.999201  -18.683715     -0.405571   \n",
       "V13     284807.0  1.693438e-15      0.995274   -5.791881     -0.648539   \n",
       "V14     284807.0  1.479045e-15      0.958596  -19.214325     -0.425574   \n",
       "V15     284807.0  3.482336e-15      0.915316   -4.498945     -0.582884   \n",
       "V16     284807.0  1.392007e-15      0.876253  -14.129855     -0.468037   \n",
       "V17     284807.0 -7.528491e-16      0.849337  -25.162799     -0.483748   \n",
       "V18     284807.0  4.328772e-16      0.838176   -9.498746     -0.498850   \n",
       "V19     284807.0  9.049732e-16      0.814041   -7.213527     -0.456299   \n",
       "V20     284807.0  5.085503e-16      0.770925  -54.497720     -0.211721   \n",
       "V21     284807.0  1.537294e-16      0.734524  -34.830382     -0.228395   \n",
       "V22     284807.0  7.959909e-16      0.725702  -10.933144     -0.542350   \n",
       "V23     284807.0  5.367590e-16      0.624460  -44.807735     -0.161846   \n",
       "V24     284807.0  4.458112e-15      0.605647   -2.836627     -0.354586   \n",
       "V25     284807.0  1.453003e-15      0.521278  -10.295397     -0.317145   \n",
       "V26     284807.0  1.699104e-15      0.482227   -2.604551     -0.326984   \n",
       "V27     284807.0 -3.660161e-16      0.403632  -22.565679     -0.070840   \n",
       "V28     284807.0 -1.206049e-16      0.330083  -15.430084     -0.052960   \n",
       "Amount  284807.0  8.834962e+01    250.120109    0.000000      5.600000   \n",
       "Class   284807.0  1.727486e-03      0.041527    0.000000      0.000000   \n",
       "\n",
       "                 50%            75%            max  \n",
       "Time    84692.000000  139320.500000  172792.000000  \n",
       "V1          0.018109       1.315642       2.454930  \n",
       "V2          0.065486       0.803724      22.057729  \n",
       "V3          0.179846       1.027196       9.382558  \n",
       "V4         -0.019847       0.743341      16.875344  \n",
       "V5         -0.054336       0.611926      34.801666  \n",
       "V6         -0.274187       0.398565      73.301626  \n",
       "V7          0.040103       0.570436     120.589494  \n",
       "V8          0.022358       0.327346      20.007208  \n",
       "V9         -0.051429       0.597139      15.594995  \n",
       "V10        -0.092917       0.453923      23.745136  \n",
       "V11        -0.032757       0.739593      12.018913  \n",
       "V12         0.140033       0.618238       7.848392  \n",
       "V13        -0.013568       0.662505       7.126883  \n",
       "V14         0.050601       0.493150      10.526766  \n",
       "V15         0.048072       0.648821       8.877742  \n",
       "V16         0.066413       0.523296      17.315112  \n",
       "V17        -0.065676       0.399675       9.253526  \n",
       "V18        -0.003636       0.500807       5.041069  \n",
       "V19         0.003735       0.458949       5.591971  \n",
       "V20        -0.062481       0.133041      39.420904  \n",
       "V21        -0.029450       0.186377      27.202839  \n",
       "V22         0.006782       0.528554      10.503090  \n",
       "V23        -0.011193       0.147642      22.528412  \n",
       "V24         0.040976       0.439527       4.584549  \n",
       "V25         0.016594       0.350716       7.519589  \n",
       "V26        -0.052139       0.240952       3.517346  \n",
       "V27         0.001342       0.091045      31.612198  \n",
       "V28         0.011244       0.078280      33.847808  \n",
       "Amount     22.000000      77.165000   25691.160000  \n",
       "Class       0.000000       0.000000       1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      "Time      284807 non-null float64\n",
      "V1        284807 non-null float64\n",
      "V2        284807 non-null float64\n",
      "V3        284807 non-null float64\n",
      "V4        284807 non-null float64\n",
      "V5        284807 non-null float64\n",
      "V6        284807 non-null float64\n",
      "V7        284807 non-null float64\n",
      "V8        284807 non-null float64\n",
      "V9        284807 non-null float64\n",
      "V10       284807 non-null float64\n",
      "V11       284807 non-null float64\n",
      "V12       284807 non-null float64\n",
      "V13       284807 non-null float64\n",
      "V14       284807 non-null float64\n",
      "V15       284807 non-null float64\n",
      "V16       284807 non-null float64\n",
      "V17       284807 non-null float64\n",
      "V18       284807 non-null float64\n",
      "V19       284807 non-null float64\n",
      "V20       284807 non-null float64\n",
      "V21       284807 non-null float64\n",
      "V22       284807 non-null float64\n",
      "V23       284807 non-null float64\n",
      "V24       284807 non-null float64\n",
      "V25       284807 non-null float64\n",
      "V26       284807 non-null float64\n",
      "V27       284807 non-null float64\n",
      "V28       284807 non-null float64\n",
      "Amount    284807 non-null float64\n",
      "Class     284807 non-null int64\n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time     -0.012323\n",
       "V1       -0.101347\n",
       "V2        0.091289\n",
       "V3       -0.192961\n",
       "V4        0.133447\n",
       "V5       -0.094974\n",
       "V6       -0.043643\n",
       "V7       -0.187257\n",
       "V8        0.019875\n",
       "V9       -0.097733\n",
       "V10      -0.216883\n",
       "V11       0.154876\n",
       "V12      -0.260593\n",
       "V13      -0.004570\n",
       "V14      -0.302544\n",
       "V15      -0.004223\n",
       "V16      -0.196539\n",
       "V17      -0.326481\n",
       "V18      -0.111485\n",
       "V19       0.034783\n",
       "V20       0.020090\n",
       "V21       0.040413\n",
       "V22       0.000805\n",
       "V23      -0.002685\n",
       "V24      -0.007221\n",
       "V25       0.003308\n",
       "V26       0.004455\n",
       "V27       0.017580\n",
       "V28       0.009536\n",
       "Amount    0.005632\n",
       "Class     1.000000\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df.drop('Time', axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fraud = df[df['Class'] == 1]\n",
    "#non_fraud = df[df['Class'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#non_fraud = non_fraud.sample(n = 1200)\n",
    "#non_fraud.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = fraud.append(non_fraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Class', axis = 1).values\n",
    "y = df['Class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    " X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model creatation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(29,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(16,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(units=1,activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=5, patience=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 213605 samples, validate on 71202 samples\n",
      "Epoch 1/600\n",
      "213605/213605 [==============================] - 3s 15us/sample - loss: 0.0539 - val_loss: 0.0090\n",
      "Epoch 2/600\n",
      "213605/213605 [==============================] - 3s 13us/sample - loss: 0.0207 - val_loss: 0.0073\n",
      "Epoch 3/600\n",
      "213605/213605 [==============================] - 3s 13us/sample - loss: 0.0153 - val_loss: 0.0071\n",
      "Epoch 4/600\n",
      "213605/213605 [==============================] - 3s 13us/sample - loss: 0.0115 - val_loss: 0.0062\n",
      "Epoch 5/600\n",
      "213605/213605 [==============================] - 6s 29us/sample - loss: 0.0105 - val_loss: 0.0047\n",
      "Epoch 6/600\n",
      "213605/213605 [==============================] - 8s 40us/sample - loss: 0.0092 - val_loss: 0.0056\n",
      "Epoch 7/600\n",
      "213605/213605 [==============================] - 8s 38us/sample - loss: 0.0090 - val_loss: 0.0047\n",
      "Epoch 8/600\n",
      "213605/213605 [==============================] - 8s 38us/sample - loss: 0.0089 - val_loss: 0.0051\n",
      "Epoch 9/600\n",
      "213605/213605 [==============================] - 8s 40us/sample - loss: 0.0088 - val_loss: 0.0055\n",
      "Epoch 10/600\n",
      "213605/213605 [==============================] - 9s 43us/sample - loss: 0.0084 - val_loss: 0.0051\n",
      "Epoch 11/600\n",
      "213605/213605 [==============================] - 9s 40us/sample - loss: 0.0088 - val_loss: 0.0053\n",
      "Epoch 12/600\n",
      "213605/213605 [==============================] - 8s 40us/sample - loss: 0.0087 - val_loss: 0.0045\n",
      "Epoch 13/600\n",
      "213605/213605 [==============================] - 8s 35us/sample - loss: 0.0083 - val_loss: 0.0046\n",
      "Epoch 14/600\n",
      "213605/213605 [==============================] - 7s 35us/sample - loss: 0.0090 - val_loss: 0.0052\n",
      "Epoch 15/600\n",
      "213605/213605 [==============================] - 8s 39us/sample - loss: 0.0087 - val_loss: 0.0049\n",
      "Epoch 16/600\n",
      "213605/213605 [==============================] - 9s 41us/sample - loss: 0.0085 - val_loss: 0.0049\n",
      "Epoch 17/600\n",
      "213605/213605 [==============================] - 10s 45us/sample - loss: 0.0088 - val_loss: 0.0052\n",
      "Epoch 18/600\n",
      "213605/213605 [==============================] - 9s 44us/sample - loss: 0.0084 - val_loss: 0.0053\n",
      "Epoch 19/600\n",
      "213605/213605 [==============================] - 7s 34us/sample - loss: 0.0087 - val_loss: 0.0051\n",
      "Epoch 20/600\n",
      "213605/213605 [==============================] - 7s 34us/sample - loss: 0.0084 - val_loss: 0.0055\n",
      "Epoch 21/600\n",
      "213605/213605 [==============================] - 7s 34us/sample - loss: 0.0085 - val_loss: 0.0048\n",
      "Epoch 22/600\n",
      "213605/213605 [==============================] - 9s 43us/sample - loss: 0.0085 - val_loss: 0.0046\n",
      "Epoch 23/600\n",
      "213605/213605 [==============================] - 9s 42us/sample - loss: 0.0086 - val_loss: 0.0052\n",
      "Epoch 24/600\n",
      "213605/213605 [==============================] - 9s 41us/sample - loss: 0.0083 - val_loss: 0.0052\n",
      "Epoch 25/600\n",
      "213605/213605 [==============================] - 9s 43us/sample - loss: 0.0085 - val_loss: 0.0049\n",
      "Epoch 26/600\n",
      "213605/213605 [==============================] - 9s 43us/sample - loss: 0.0086 - val_loss: 0.0047\n",
      "Epoch 27/600\n",
      "213605/213605 [==============================] - 10s 48us/sample - loss: 0.0085 - val_loss: 0.0050\n",
      "Epoch 28/600\n",
      "213605/213605 [==============================] - 8s 39us/sample - loss: 0.0082 - val_loss: 0.0049\n",
      "Epoch 29/600\n",
      "213605/213605 [==============================] - 10s 45us/sample - loss: 0.0080 - val_loss: 0.0048\n",
      "Epoch 30/600\n",
      "213605/213605 [==============================] - 7s 34us/sample - loss: 0.0083 - val_loss: 0.0044\n",
      "Epoch 31/600\n",
      "213605/213605 [==============================] - 9s 43us/sample - loss: 0.0082 - val_loss: 0.0058\n",
      "Epoch 32/600\n",
      "213605/213605 [==============================] - 9s 43us/sample - loss: 0.0080 - val_loss: 0.0062\n",
      "Epoch 33/600\n",
      "213605/213605 [==============================] - 9s 42us/sample - loss: 0.0081 - val_loss: 0.0054\n",
      "Epoch 34/600\n",
      "213605/213605 [==============================] - 9s 40us/sample - loss: 0.0084 - val_loss: 0.0047\n",
      "Epoch 35/600\n",
      "213605/213605 [==============================] - 9s 41us/sample - loss: 0.0083 - val_loss: 0.0047\n",
      "Epoch 36/600\n",
      "213605/213605 [==============================] - 9s 42us/sample - loss: 0.0085 - val_loss: 0.0050\n",
      "Epoch 37/600\n",
      "213605/213605 [==============================] - 9s 42us/sample - loss: 0.0084 - val_loss: 0.0051\n",
      "Epoch 38/600\n",
      "213605/213605 [==============================] - 9s 41us/sample - loss: 0.0080 - val_loss: 0.0064\n",
      "Epoch 39/600\n",
      "213605/213605 [==============================] - 9s 40us/sample - loss: 0.0080 - val_loss: 0.0049\n",
      "Epoch 40/600\n",
      "213605/213605 [==============================] - 9s 41us/sample - loss: 0.0081 - val_loss: 0.0045\n",
      "Epoch 41/600\n",
      "213605/213605 [==============================] - 8s 37us/sample - loss: 0.0084 - val_loss: 0.0046\n",
      "Epoch 42/600\n",
      "213605/213605 [==============================] - 8s 37us/sample - loss: 0.0079 - val_loss: 0.0044\n",
      "Epoch 43/600\n",
      "213605/213605 [==============================] - 10s 46us/sample - loss: 0.0081 - val_loss: 0.0044\n",
      "Epoch 44/600\n",
      "213605/213605 [==============================] - 9s 41us/sample - loss: 0.0084 - val_loss: 0.0047\n",
      "Epoch 45/600\n",
      "213605/213605 [==============================] - 10s 45us/sample - loss: 0.0082 - val_loss: 0.0047\n",
      "Epoch 46/600\n",
      "213605/213605 [==============================] - 9s 40us/sample - loss: 0.0082 - val_loss: 0.0047\n",
      "Epoch 47/600\n",
      "213605/213605 [==============================] - 8s 36us/sample - loss: 0.0081 - val_loss: 0.0052\n",
      "Epoch 48/600\n",
      "213605/213605 [==============================] - 9s 41us/sample - loss: 0.0081 - val_loss: 0.0049\n",
      "Epoch 49/600\n",
      "213605/213605 [==============================] - 8s 36us/sample - loss: 0.0078 - val_loss: 0.0047\n",
      "Epoch 50/600\n",
      "213605/213605 [==============================] - 8s 38us/sample - loss: 0.0076 - val_loss: 0.0043\n",
      "Epoch 51/600\n",
      "213605/213605 [==============================] - 10s 45us/sample - loss: 0.0079 - val_loss: 0.0046\n",
      "Epoch 52/600\n",
      "213605/213605 [==============================] - 8s 39us/sample - loss: 0.0081 - val_loss: 0.0046\n",
      "Epoch 53/600\n",
      "213605/213605 [==============================] - 10s 47us/sample - loss: 0.0079 - val_loss: 0.0044\n",
      "Epoch 54/600\n",
      "213605/213605 [==============================] - 10s 45us/sample - loss: 0.0078 - val_loss: 0.0049\n",
      "Epoch 55/600\n",
      "213605/213605 [==============================] - 9s 41us/sample - loss: 0.0080 - val_loss: 0.0054\n",
      "Epoch 56/600\n",
      "213605/213605 [==============================] - 9s 42us/sample - loss: 0.0080 - val_loss: 0.0043\n",
      "Epoch 57/600\n",
      "213605/213605 [==============================] - 9s 43us/sample - loss: 0.0083 - val_loss: 0.0045\n",
      "Epoch 58/600\n",
      "213605/213605 [==============================] - 9s 43us/sample - loss: 0.0080 - val_loss: 0.0047\n",
      "Epoch 59/600\n",
      "213605/213605 [==============================] - 10s 46us/sample - loss: 0.0081 - val_loss: 0.0043\n",
      "Epoch 60/600\n",
      "213605/213605 [==============================] - 8s 39us/sample - loss: 0.0080 - val_loss: 0.0049\n",
      "Epoch 61/600\n",
      "213605/213605 [==============================] - 9s 40us/sample - loss: 0.0080 - val_loss: 0.0055\n",
      "Epoch 62/600\n",
      "213605/213605 [==============================] - 8s 40us/sample - loss: 0.0079 - val_loss: 0.0045\n",
      "Epoch 63/600\n",
      "213605/213605 [==============================] - 11s 49us/sample - loss: 0.0079 - val_loss: 0.0052\n",
      "Epoch 64/600\n",
      "213605/213605 [==============================] - 7s 33us/sample - loss: 0.0080 - val_loss: 0.0050\n",
      "Epoch 65/600\n",
      "213605/213605 [==============================] - 8s 39us/sample - loss: 0.0077 - val_loss: 0.0046\n",
      "Epoch 66/600\n",
      "213605/213605 [==============================] - 8s 39us/sample - loss: 0.0077 - val_loss: 0.0045\n",
      "Epoch 67/600\n",
      "213605/213605 [==============================] - 10s 47us/sample - loss: 0.0078 - val_loss: 0.0045\n",
      "Epoch 68/600\n",
      "213605/213605 [==============================] - 9s 44us/sample - loss: 0.0078 - val_loss: 0.0046\n",
      "Epoch 69/600\n",
      "213605/213605 [==============================] - 8s 39us/sample - loss: 0.0077 - val_loss: 0.0044\n",
      "Epoch 70/600\n",
      "213605/213605 [==============================] - 9s 44us/sample - loss: 0.0076 - val_loss: 0.0048\n",
      "Epoch 71/600\n",
      "213605/213605 [==============================] - 10s 46us/sample - loss: 0.0081 - val_loss: 0.0046\n",
      "Epoch 72/600\n",
      "213605/213605 [==============================] - 8s 36us/sample - loss: 0.0078 - val_loss: 0.0046\n",
      "Epoch 73/600\n",
      "213605/213605 [==============================] - 8s 38us/sample - loss: 0.0078 - val_loss: 0.0056\n",
      "Epoch 74/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213605/213605 [==============================] - 9s 41us/sample - loss: 0.0082 - val_loss: 0.0049\n",
      "Epoch 75/600\n",
      "213605/213605 [==============================] - 8s 39us/sample - loss: 0.0080 - val_loss: 0.0044\n",
      "Epoch 76/600\n",
      "213605/213605 [==============================] - 9s 40us/sample - loss: 0.0082 - val_loss: 0.0046\n",
      "Epoch 77/600\n",
      "213605/213605 [==============================] - 9s 42us/sample - loss: 0.0077 - val_loss: 0.0046\n",
      "Epoch 78/600\n",
      "213605/213605 [==============================] - 10s 48us/sample - loss: 0.0079 - val_loss: 0.0046\n",
      "Epoch 79/600\n",
      "213605/213605 [==============================] - 10s 47us/sample - loss: 0.0077 - val_loss: 0.0041\n",
      "Epoch 80/600\n",
      "213605/213605 [==============================] - 9s 43us/sample - loss: 0.0080 - val_loss: 0.0047\n",
      "Epoch 81/600\n",
      "213605/213605 [==============================] - 9s 44us/sample - loss: 0.0077 - val_loss: 0.0044\n",
      "Epoch 82/600\n",
      "213605/213605 [==============================] - 10s 48us/sample - loss: 0.0078 - val_loss: 0.0047\n",
      "Epoch 83/600\n",
      "213605/213605 [==============================] - 10s 48us/sample - loss: 0.0080 - val_loss: 0.0045\n",
      "Epoch 84/600\n",
      "213605/213605 [==============================] - 8s 39us/sample - loss: 0.0078 - val_loss: 0.0050\n",
      "Epoch 85/600\n",
      "213605/213605 [==============================] - 11s 49us/sample - loss: 0.0081 - val_loss: 0.0048\n",
      "Epoch 86/600\n",
      "213605/213605 [==============================] - 9s 42us/sample - loss: 0.0082 - val_loss: 0.0047\n",
      "Epoch 87/600\n",
      "213605/213605 [==============================] - 7s 33us/sample - loss: 0.0077 - val_loss: 0.0049\n",
      "Epoch 88/600\n",
      "213605/213605 [==============================] - 7s 35us/sample - loss: 0.0083 - val_loss: 0.0043\n",
      "Epoch 89/600\n",
      "213605/213605 [==============================] - 9s 43us/sample - loss: 0.0078 - val_loss: 0.0047\n",
      "Epoch 90/600\n",
      "213605/213605 [==============================] - 9s 44us/sample - loss: 0.0080 - val_loss: 0.0048\n",
      "Epoch 91/600\n",
      "213605/213605 [==============================] - 9s 43us/sample - loss: 0.0078 - val_loss: 0.0042\n",
      "Epoch 92/600\n",
      "213605/213605 [==============================] - 9s 41us/sample - loss: 0.0079 - val_loss: 0.0044\n",
      "Epoch 93/600\n",
      "213605/213605 [==============================] - 9s 40us/sample - loss: 0.0081 - val_loss: 0.0049\n",
      "Epoch 94/600\n",
      "213605/213605 [==============================] - 9s 41us/sample - loss: 0.0079 - val_loss: 0.0043\n",
      "Epoch 95/600\n",
      "213605/213605 [==============================] - 9s 44us/sample - loss: 0.0076 - val_loss: 0.0047\n",
      "Epoch 96/600\n",
      "213605/213605 [==============================] - 10s 45us/sample - loss: 0.0083 - val_loss: 0.0049\n",
      "Epoch 97/600\n",
      "213605/213605 [==============================] - 8s 37us/sample - loss: 0.0078 - val_loss: 0.0044\n",
      "Epoch 98/600\n",
      "213605/213605 [==============================] - 10s 49us/sample - loss: 0.0080 - val_loss: 0.0049\n",
      "Epoch 99/600\n",
      "213605/213605 [==============================] - 9s 42us/sample - loss: 0.0080 - val_loss: 0.0046\n",
      "Epoch 100/600\n",
      "213605/213605 [==============================] - 10s 47us/sample - loss: 0.0078 - val_loss: 0.0049\n",
      "Epoch 101/600\n",
      "213605/213605 [==============================] - 9s 43us/sample - loss: 0.0080 - val_loss: 0.0047\n",
      "Epoch 102/600\n",
      "213605/213605 [==============================] - 9s 43us/sample - loss: 0.0078 - val_loss: 0.0049\n",
      "Epoch 103/600\n",
      "213605/213605 [==============================] - 10s 48us/sample - loss: 0.0078 - val_loss: 0.0047\n",
      "Epoch 104/600\n",
      "213605/213605 [==============================] - 8s 40us/sample - loss: 0.0077 - val_loss: 0.0045\n",
      "Epoch 105/600\n",
      "213605/213605 [==============================] - 11s 50us/sample - loss: 0.0078 - val_loss: 0.0041\n",
      "Epoch 106/600\n",
      "213605/213605 [==============================] - 9s 44us/sample - loss: 0.0079 - val_loss: 0.0045\n",
      "Epoch 107/600\n",
      "213605/213605 [==============================] - 10s 45us/sample - loss: 0.0078 - val_loss: 0.0048\n",
      "Epoch 108/600\n",
      "213605/213605 [==============================] - 8s 40us/sample - loss: 0.0076 - val_loss: 0.0043\n",
      "Epoch 109/600\n",
      "213605/213605 [==============================] - 9s 42us/sample - loss: 0.0074 - val_loss: 0.0045\n",
      "Epoch 110/600\n",
      "213605/213605 [==============================] - 9s 44us/sample - loss: 0.0077 - val_loss: 0.0050\n",
      "Epoch 111/600\n",
      "213605/213605 [==============================] - 10s 48us/sample - loss: 0.0077 - val_loss: 0.0043\n",
      "Epoch 112/600\n",
      "213605/213605 [==============================] - 9s 42us/sample - loss: 0.0076 - val_loss: 0.0052\n",
      "Epoch 113/600\n",
      "213605/213605 [==============================] - 9s 40us/sample - loss: 0.0081 - val_loss: 0.0044\n",
      "Epoch 114/600\n",
      "213605/213605 [==============================] - 10s 48us/sample - loss: 0.0079 - val_loss: 0.0040\n",
      "Epoch 115/600\n",
      "213605/213605 [==============================] - 11s 53us/sample - loss: 0.0078 - val_loss: 0.0045\n",
      "Epoch 116/600\n",
      "213605/213605 [==============================] - 8s 38us/sample - loss: 0.0077 - val_loss: 0.0042\n",
      "Epoch 117/600\n",
      "213605/213605 [==============================] - 9s 41us/sample - loss: 0.0077 - val_loss: 0.0048\n",
      "Epoch 118/600\n",
      "213605/213605 [==============================] - 10s 45us/sample - loss: 0.0081 - val_loss: 0.0046\n",
      "Epoch 119/600\n",
      "213605/213605 [==============================] - 9s 41us/sample - loss: 0.0078 - val_loss: 0.0045\n",
      "Epoch 120/600\n",
      "213605/213605 [==============================] - 8s 39us/sample - loss: 0.0081 - val_loss: 0.0042\n",
      "Epoch 121/600\n",
      "213605/213605 [==============================] - 9s 43us/sample - loss: 0.0075 - val_loss: 0.0044\n",
      "Epoch 122/600\n",
      "213605/213605 [==============================] - 10s 45us/sample - loss: 0.0075 - val_loss: 0.0041\n",
      "Epoch 123/600\n",
      "213605/213605 [==============================] - 10s 47us/sample - loss: 0.0075 - val_loss: 0.0047\n",
      "Epoch 124/600\n",
      "213605/213605 [==============================] - 9s 40us/sample - loss: 0.0078 - val_loss: 0.0045\n",
      "Epoch 125/600\n",
      "213605/213605 [==============================] - 10s 46us/sample - loss: 0.0074 - val_loss: 0.0055\n",
      "Epoch 126/600\n",
      "213605/213605 [==============================] - 9s 43us/sample - loss: 0.0079 - val_loss: 0.0050\n",
      "Epoch 127/600\n",
      "213605/213605 [==============================] - 9s 40us/sample - loss: 0.0080 - val_loss: 0.0049\n",
      "Epoch 128/600\n",
      "213605/213605 [==============================] - 8s 37us/sample - loss: 0.0078 - val_loss: 0.0046\n",
      "Epoch 129/600\n",
      "213605/213605 [==============================] - 9s 41us/sample - loss: 0.0079 - val_loss: 0.0042\n",
      "Epoch 130/600\n",
      "213605/213605 [==============================] - 8s 39us/sample - loss: 0.0075 - val_loss: 0.0043\n",
      "Epoch 131/600\n",
      "213605/213605 [==============================] - 9s 41us/sample - loss: 0.0075 - val_loss: 0.0054\n",
      "Epoch 132/600\n",
      "213605/213605 [==============================] - 10s 46us/sample - loss: 0.0078 - val_loss: 0.0044\n",
      "Epoch 133/600\n",
      "213605/213605 [==============================] - 9s 41us/sample - loss: 0.0081 - val_loss: 0.0049\n",
      "Epoch 134/600\n",
      "213605/213605 [==============================] - 10s 47us/sample - loss: 0.0076 - val_loss: 0.0043\n",
      "Epoch 135/600\n",
      "213605/213605 [==============================] - 9s 44us/sample - loss: 0.0078 - val_loss: 0.0043\n",
      "Epoch 136/600\n",
      "213605/213605 [==============================] - 9s 44us/sample - loss: 0.0077 - val_loss: 0.0049\n",
      "Epoch 137/600\n",
      "213605/213605 [==============================] - 9s 43us/sample - loss: 0.0077 - val_loss: 0.0050\n",
      "Epoch 138/600\n",
      "213605/213605 [==============================] - 11s 51us/sample - loss: 0.0077 - val_loss: 0.0045\n",
      "Epoch 139/600\n",
      "213605/213605 [==============================] - 10s 46us/sample - loss: 0.0078 - val_loss: 0.0041\n",
      "Epoch 140/600\n",
      "213605/213605 [==============================] - 11s 49us/sample - loss: 0.0073 - val_loss: 0.0040\n",
      "Epoch 141/600\n",
      "213605/213605 [==============================] - 9s 43us/sample - loss: 0.0075 - val_loss: 0.0043\n",
      "Epoch 142/600\n",
      "213605/213605 [==============================] - 8s 39us/sample - loss: 0.0075 - val_loss: 0.0041\n",
      "Epoch 143/600\n",
      "213605/213605 [==============================] - 9s 41us/sample - loss: 0.0078 - val_loss: 0.0047\n",
      "Epoch 144/600\n",
      "213605/213605 [==============================] - 9s 44us/sample - loss: 0.0079 - val_loss: 0.0049\n",
      "Epoch 145/600\n",
      "213605/213605 [==============================] - 8s 38us/sample - loss: 0.0075 - val_loss: 0.0044\n",
      "Epoch 146/600\n",
      "213605/213605 [==============================] - 10s 45us/sample - loss: 0.0077 - val_loss: 0.0048\n",
      "Epoch 147/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213605/213605 [==============================] - 10s 46us/sample - loss: 0.0079 - val_loss: 0.0051\n",
      "Epoch 148/600\n",
      "213605/213605 [==============================] - 10s 45us/sample - loss: 0.0074 - val_loss: 0.0044\n",
      "Epoch 149/600\n",
      "213605/213605 [==============================] - 9s 44us/sample - loss: 0.0075 - val_loss: 0.0041\n",
      "Epoch 150/600\n",
      "213605/213605 [==============================] - 9s 42us/sample - loss: 0.0077 - val_loss: 0.0041\n",
      "Epoch 151/600\n",
      "213605/213605 [==============================] - 9s 43us/sample - loss: 0.0076 - val_loss: 0.0044\n",
      "Epoch 152/600\n",
      "213605/213605 [==============================] - 7s 32us/sample - loss: 0.0075 - val_loss: 0.0042\n",
      "Epoch 153/600\n",
      "213605/213605 [==============================] - 8s 36us/sample - loss: 0.0078 - val_loss: 0.0046\n",
      "Epoch 154/600\n",
      "213605/213605 [==============================] - 10s 45us/sample - loss: 0.0078 - val_loss: 0.0042\n",
      "Epoch 155/600\n",
      "213605/213605 [==============================] - 10s 49us/sample - loss: 0.0076 - val_loss: 0.0045\n",
      "Epoch 156/600\n",
      "213605/213605 [==============================] - 10s 49us/sample - loss: 0.0076 - val_loss: 0.0044\n",
      "Epoch 157/600\n",
      "213605/213605 [==============================] - 10s 46us/sample - loss: 0.0075 - val_loss: 0.0044\n",
      "Epoch 158/600\n",
      "213605/213605 [==============================] - 9s 44us/sample - loss: 0.0077 - val_loss: 0.0047\n",
      "Epoch 159/600\n",
      "213605/213605 [==============================] - 10s 46us/sample - loss: 0.0078 - val_loss: 0.0044\n",
      "Epoch 160/600\n",
      "213605/213605 [==============================] - 8s 35us/sample - loss: 0.0074 - val_loss: 0.0047\n",
      "Epoch 161/600\n",
      "213605/213605 [==============================] - 9s 40us/sample - loss: 0.0076 - val_loss: 0.0042\n",
      "Epoch 162/600\n",
      "213605/213605 [==============================] - 8s 39us/sample - loss: 0.0075 - val_loss: 0.0042\n",
      "Epoch 163/600\n",
      "213605/213605 [==============================] - 12s 54us/sample - loss: 0.0076 - val_loss: 0.0052\n",
      "Epoch 164/600\n",
      "213605/213605 [==============================] - 10s 47us/sample - loss: 0.0076 - val_loss: 0.0049\n",
      "Epoch 165/600\n",
      "213605/213605 [==============================] - 8s 40us/sample - loss: 0.0076 - val_loss: 0.0041\n",
      "Epoch 166/600\n",
      "213605/213605 [==============================] - 11s 49us/sample - loss: 0.0075 - val_loss: 0.0044\n",
      "Epoch 167/600\n",
      "213605/213605 [==============================] - 10s 47us/sample - loss: 0.0072 - val_loss: 0.0050\n",
      "Epoch 168/600\n",
      "213605/213605 [==============================] - 8s 39us/sample - loss: 0.0076 - val_loss: 0.0044\n",
      "Epoch 169/600\n",
      "213605/213605 [==============================] - 9s 43us/sample - loss: 0.0077 - val_loss: 0.0043\n",
      "Epoch 170/600\n",
      "213605/213605 [==============================] - 9s 43us/sample - loss: 0.0075 - val_loss: 0.0042\n",
      "Epoch 171/600\n",
      "213605/213605 [==============================] - 10s 45us/sample - loss: 0.0074 - val_loss: 0.0040\n",
      "Epoch 172/600\n",
      "213605/213605 [==============================] - 9s 44us/sample - loss: 0.0076 - val_loss: 0.0047\n",
      "Epoch 173/600\n",
      "213605/213605 [==============================] - 9s 42us/sample - loss: 0.0078 - val_loss: 0.0048\n",
      "Epoch 174/600\n",
      "213605/213605 [==============================] - 8s 39us/sample - loss: 0.0079 - val_loss: 0.0043\n",
      "Epoch 175/600\n",
      "213605/213605 [==============================] - 9s 43us/sample - loss: 0.0075 - val_loss: 0.0046\n",
      "Epoch 00175: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d3be3a9eb8>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, \n",
    "          y=y_train, \n",
    "          epochs=600,\n",
    "          batch_size= 128,\n",
    "          validation_data=(X_test, y_test), verbose=1,\n",
    "          callbacks=[early_stop]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1d3bea61e80>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_loss = pd.DataFrame(model.history.history)\n",
    "model_loss.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     71089\n",
      "           1       0.00      0.00      0.00       113\n",
      "\n",
      "    accuracy                           1.00     71202\n",
      "   macro avg       0.50      0.50      0.50     71202\n",
      "weighted avg       1.00      1.00      1.00     71202\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JOrlo\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[71089     0]\n",
      " [  113     0]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
