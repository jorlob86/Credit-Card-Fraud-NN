{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection using Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import of Libaries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  pd.read_csv('creditcard.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>9.481386e+04</td>\n",
       "      <td>47488.145955</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54201.500000</td>\n",
       "      <td>84692.000000</td>\n",
       "      <td>139320.500000</td>\n",
       "      <td>172792.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>3.919560e-15</td>\n",
       "      <td>1.958696</td>\n",
       "      <td>-56.407510</td>\n",
       "      <td>-0.920373</td>\n",
       "      <td>0.018109</td>\n",
       "      <td>1.315642</td>\n",
       "      <td>2.454930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V2</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>5.688174e-16</td>\n",
       "      <td>1.651309</td>\n",
       "      <td>-72.715728</td>\n",
       "      <td>-0.598550</td>\n",
       "      <td>0.065486</td>\n",
       "      <td>0.803724</td>\n",
       "      <td>22.057729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V3</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-8.769071e-15</td>\n",
       "      <td>1.516255</td>\n",
       "      <td>-48.325589</td>\n",
       "      <td>-0.890365</td>\n",
       "      <td>0.179846</td>\n",
       "      <td>1.027196</td>\n",
       "      <td>9.382558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V4</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>2.782312e-15</td>\n",
       "      <td>1.415869</td>\n",
       "      <td>-5.683171</td>\n",
       "      <td>-0.848640</td>\n",
       "      <td>-0.019847</td>\n",
       "      <td>0.743341</td>\n",
       "      <td>16.875344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V5</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-1.552563e-15</td>\n",
       "      <td>1.380247</td>\n",
       "      <td>-113.743307</td>\n",
       "      <td>-0.691597</td>\n",
       "      <td>-0.054336</td>\n",
       "      <td>0.611926</td>\n",
       "      <td>34.801666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V6</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>2.010663e-15</td>\n",
       "      <td>1.332271</td>\n",
       "      <td>-26.160506</td>\n",
       "      <td>-0.768296</td>\n",
       "      <td>-0.274187</td>\n",
       "      <td>0.398565</td>\n",
       "      <td>73.301626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V7</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-1.694249e-15</td>\n",
       "      <td>1.237094</td>\n",
       "      <td>-43.557242</td>\n",
       "      <td>-0.554076</td>\n",
       "      <td>0.040103</td>\n",
       "      <td>0.570436</td>\n",
       "      <td>120.589494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V8</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-1.927028e-16</td>\n",
       "      <td>1.194353</td>\n",
       "      <td>-73.216718</td>\n",
       "      <td>-0.208630</td>\n",
       "      <td>0.022358</td>\n",
       "      <td>0.327346</td>\n",
       "      <td>20.007208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V9</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-3.137024e-15</td>\n",
       "      <td>1.098632</td>\n",
       "      <td>-13.434066</td>\n",
       "      <td>-0.643098</td>\n",
       "      <td>-0.051429</td>\n",
       "      <td>0.597139</td>\n",
       "      <td>15.594995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V10</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.768627e-15</td>\n",
       "      <td>1.088850</td>\n",
       "      <td>-24.588262</td>\n",
       "      <td>-0.535426</td>\n",
       "      <td>-0.092917</td>\n",
       "      <td>0.453923</td>\n",
       "      <td>23.745136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V11</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>9.170318e-16</td>\n",
       "      <td>1.020713</td>\n",
       "      <td>-4.797473</td>\n",
       "      <td>-0.762494</td>\n",
       "      <td>-0.032757</td>\n",
       "      <td>0.739593</td>\n",
       "      <td>12.018913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V12</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-1.810658e-15</td>\n",
       "      <td>0.999201</td>\n",
       "      <td>-18.683715</td>\n",
       "      <td>-0.405571</td>\n",
       "      <td>0.140033</td>\n",
       "      <td>0.618238</td>\n",
       "      <td>7.848392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V13</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.693438e-15</td>\n",
       "      <td>0.995274</td>\n",
       "      <td>-5.791881</td>\n",
       "      <td>-0.648539</td>\n",
       "      <td>-0.013568</td>\n",
       "      <td>0.662505</td>\n",
       "      <td>7.126883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V14</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.479045e-15</td>\n",
       "      <td>0.958596</td>\n",
       "      <td>-19.214325</td>\n",
       "      <td>-0.425574</td>\n",
       "      <td>0.050601</td>\n",
       "      <td>0.493150</td>\n",
       "      <td>10.526766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V15</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>3.482336e-15</td>\n",
       "      <td>0.915316</td>\n",
       "      <td>-4.498945</td>\n",
       "      <td>-0.582884</td>\n",
       "      <td>0.048072</td>\n",
       "      <td>0.648821</td>\n",
       "      <td>8.877742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V16</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.392007e-15</td>\n",
       "      <td>0.876253</td>\n",
       "      <td>-14.129855</td>\n",
       "      <td>-0.468037</td>\n",
       "      <td>0.066413</td>\n",
       "      <td>0.523296</td>\n",
       "      <td>17.315112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V17</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-7.528491e-16</td>\n",
       "      <td>0.849337</td>\n",
       "      <td>-25.162799</td>\n",
       "      <td>-0.483748</td>\n",
       "      <td>-0.065676</td>\n",
       "      <td>0.399675</td>\n",
       "      <td>9.253526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V18</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>4.328772e-16</td>\n",
       "      <td>0.838176</td>\n",
       "      <td>-9.498746</td>\n",
       "      <td>-0.498850</td>\n",
       "      <td>-0.003636</td>\n",
       "      <td>0.500807</td>\n",
       "      <td>5.041069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V19</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>9.049732e-16</td>\n",
       "      <td>0.814041</td>\n",
       "      <td>-7.213527</td>\n",
       "      <td>-0.456299</td>\n",
       "      <td>0.003735</td>\n",
       "      <td>0.458949</td>\n",
       "      <td>5.591971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V20</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>5.085503e-16</td>\n",
       "      <td>0.770925</td>\n",
       "      <td>-54.497720</td>\n",
       "      <td>-0.211721</td>\n",
       "      <td>-0.062481</td>\n",
       "      <td>0.133041</td>\n",
       "      <td>39.420904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V21</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.537294e-16</td>\n",
       "      <td>0.734524</td>\n",
       "      <td>-34.830382</td>\n",
       "      <td>-0.228395</td>\n",
       "      <td>-0.029450</td>\n",
       "      <td>0.186377</td>\n",
       "      <td>27.202839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V22</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>7.959909e-16</td>\n",
       "      <td>0.725702</td>\n",
       "      <td>-10.933144</td>\n",
       "      <td>-0.542350</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>0.528554</td>\n",
       "      <td>10.503090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V23</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>5.367590e-16</td>\n",
       "      <td>0.624460</td>\n",
       "      <td>-44.807735</td>\n",
       "      <td>-0.161846</td>\n",
       "      <td>-0.011193</td>\n",
       "      <td>0.147642</td>\n",
       "      <td>22.528412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V24</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>4.458112e-15</td>\n",
       "      <td>0.605647</td>\n",
       "      <td>-2.836627</td>\n",
       "      <td>-0.354586</td>\n",
       "      <td>0.040976</td>\n",
       "      <td>0.439527</td>\n",
       "      <td>4.584549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V25</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.453003e-15</td>\n",
       "      <td>0.521278</td>\n",
       "      <td>-10.295397</td>\n",
       "      <td>-0.317145</td>\n",
       "      <td>0.016594</td>\n",
       "      <td>0.350716</td>\n",
       "      <td>7.519589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V26</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.699104e-15</td>\n",
       "      <td>0.482227</td>\n",
       "      <td>-2.604551</td>\n",
       "      <td>-0.326984</td>\n",
       "      <td>-0.052139</td>\n",
       "      <td>0.240952</td>\n",
       "      <td>3.517346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V27</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-3.660161e-16</td>\n",
       "      <td>0.403632</td>\n",
       "      <td>-22.565679</td>\n",
       "      <td>-0.070840</td>\n",
       "      <td>0.001342</td>\n",
       "      <td>0.091045</td>\n",
       "      <td>31.612198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V28</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-1.206049e-16</td>\n",
       "      <td>0.330083</td>\n",
       "      <td>-15.430084</td>\n",
       "      <td>-0.052960</td>\n",
       "      <td>0.011244</td>\n",
       "      <td>0.078280</td>\n",
       "      <td>33.847808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amount</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>8.834962e+01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>25691.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.727486e-03</td>\n",
       "      <td>0.041527</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count          mean           std         min           25%  \\\n",
       "Time    284807.0  9.481386e+04  47488.145955    0.000000  54201.500000   \n",
       "V1      284807.0  3.919560e-15      1.958696  -56.407510     -0.920373   \n",
       "V2      284807.0  5.688174e-16      1.651309  -72.715728     -0.598550   \n",
       "V3      284807.0 -8.769071e-15      1.516255  -48.325589     -0.890365   \n",
       "V4      284807.0  2.782312e-15      1.415869   -5.683171     -0.848640   \n",
       "V5      284807.0 -1.552563e-15      1.380247 -113.743307     -0.691597   \n",
       "V6      284807.0  2.010663e-15      1.332271  -26.160506     -0.768296   \n",
       "V7      284807.0 -1.694249e-15      1.237094  -43.557242     -0.554076   \n",
       "V8      284807.0 -1.927028e-16      1.194353  -73.216718     -0.208630   \n",
       "V9      284807.0 -3.137024e-15      1.098632  -13.434066     -0.643098   \n",
       "V10     284807.0  1.768627e-15      1.088850  -24.588262     -0.535426   \n",
       "V11     284807.0  9.170318e-16      1.020713   -4.797473     -0.762494   \n",
       "V12     284807.0 -1.810658e-15      0.999201  -18.683715     -0.405571   \n",
       "V13     284807.0  1.693438e-15      0.995274   -5.791881     -0.648539   \n",
       "V14     284807.0  1.479045e-15      0.958596  -19.214325     -0.425574   \n",
       "V15     284807.0  3.482336e-15      0.915316   -4.498945     -0.582884   \n",
       "V16     284807.0  1.392007e-15      0.876253  -14.129855     -0.468037   \n",
       "V17     284807.0 -7.528491e-16      0.849337  -25.162799     -0.483748   \n",
       "V18     284807.0  4.328772e-16      0.838176   -9.498746     -0.498850   \n",
       "V19     284807.0  9.049732e-16      0.814041   -7.213527     -0.456299   \n",
       "V20     284807.0  5.085503e-16      0.770925  -54.497720     -0.211721   \n",
       "V21     284807.0  1.537294e-16      0.734524  -34.830382     -0.228395   \n",
       "V22     284807.0  7.959909e-16      0.725702  -10.933144     -0.542350   \n",
       "V23     284807.0  5.367590e-16      0.624460  -44.807735     -0.161846   \n",
       "V24     284807.0  4.458112e-15      0.605647   -2.836627     -0.354586   \n",
       "V25     284807.0  1.453003e-15      0.521278  -10.295397     -0.317145   \n",
       "V26     284807.0  1.699104e-15      0.482227   -2.604551     -0.326984   \n",
       "V27     284807.0 -3.660161e-16      0.403632  -22.565679     -0.070840   \n",
       "V28     284807.0 -1.206049e-16      0.330083  -15.430084     -0.052960   \n",
       "Amount  284807.0  8.834962e+01    250.120109    0.000000      5.600000   \n",
       "Class   284807.0  1.727486e-03      0.041527    0.000000      0.000000   \n",
       "\n",
       "                 50%            75%            max  \n",
       "Time    84692.000000  139320.500000  172792.000000  \n",
       "V1          0.018109       1.315642       2.454930  \n",
       "V2          0.065486       0.803724      22.057729  \n",
       "V3          0.179846       1.027196       9.382558  \n",
       "V4         -0.019847       0.743341      16.875344  \n",
       "V5         -0.054336       0.611926      34.801666  \n",
       "V6         -0.274187       0.398565      73.301626  \n",
       "V7          0.040103       0.570436     120.589494  \n",
       "V8          0.022358       0.327346      20.007208  \n",
       "V9         -0.051429       0.597139      15.594995  \n",
       "V10        -0.092917       0.453923      23.745136  \n",
       "V11        -0.032757       0.739593      12.018913  \n",
       "V12         0.140033       0.618238       7.848392  \n",
       "V13        -0.013568       0.662505       7.126883  \n",
       "V14         0.050601       0.493150      10.526766  \n",
       "V15         0.048072       0.648821       8.877742  \n",
       "V16         0.066413       0.523296      17.315112  \n",
       "V17        -0.065676       0.399675       9.253526  \n",
       "V18        -0.003636       0.500807       5.041069  \n",
       "V19         0.003735       0.458949       5.591971  \n",
       "V20        -0.062481       0.133041      39.420904  \n",
       "V21        -0.029450       0.186377      27.202839  \n",
       "V22         0.006782       0.528554      10.503090  \n",
       "V23        -0.011193       0.147642      22.528412  \n",
       "V24         0.040976       0.439527       4.584549  \n",
       "V25         0.016594       0.350716       7.519589  \n",
       "V26        -0.052139       0.240952       3.517346  \n",
       "V27         0.001342       0.091045      31.612198  \n",
       "V28         0.011244       0.078280      33.847808  \n",
       "Amount     22.000000      77.165000   25691.160000  \n",
       "Class       0.000000       0.000000       1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      "Time      284807 non-null float64\n",
      "V1        284807 non-null float64\n",
      "V2        284807 non-null float64\n",
      "V3        284807 non-null float64\n",
      "V4        284807 non-null float64\n",
      "V5        284807 non-null float64\n",
      "V6        284807 non-null float64\n",
      "V7        284807 non-null float64\n",
      "V8        284807 non-null float64\n",
      "V9        284807 non-null float64\n",
      "V10       284807 non-null float64\n",
      "V11       284807 non-null float64\n",
      "V12       284807 non-null float64\n",
      "V13       284807 non-null float64\n",
      "V14       284807 non-null float64\n",
      "V15       284807 non-null float64\n",
      "V16       284807 non-null float64\n",
      "V17       284807 non-null float64\n",
      "V18       284807 non-null float64\n",
      "V19       284807 non-null float64\n",
      "V20       284807 non-null float64\n",
      "V21       284807 non-null float64\n",
      "V22       284807 non-null float64\n",
      "V23       284807 non-null float64\n",
      "V24       284807 non-null float64\n",
      "V25       284807 non-null float64\n",
      "V26       284807 non-null float64\n",
      "V27       284807 non-null float64\n",
      "V28       284807 non-null float64\n",
      "Amount    284807 non-null float64\n",
      "Class     284807 non-null int64\n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time     -0.012323\n",
       "V1       -0.101347\n",
       "V2        0.091289\n",
       "V3       -0.192961\n",
       "V4        0.133447\n",
       "V5       -0.094974\n",
       "V6       -0.043643\n",
       "V7       -0.187257\n",
       "V8        0.019875\n",
       "V9       -0.097733\n",
       "V10      -0.216883\n",
       "V11       0.154876\n",
       "V12      -0.260593\n",
       "V13      -0.004570\n",
       "V14      -0.302544\n",
       "V15      -0.004223\n",
       "V16      -0.196539\n",
       "V17      -0.326481\n",
       "V18      -0.111485\n",
       "V19       0.034783\n",
       "V20       0.020090\n",
       "V21       0.040413\n",
       "V22       0.000805\n",
       "V23      -0.002685\n",
       "V24      -0.007221\n",
       "V25       0.003308\n",
       "V26       0.004455\n",
       "V27       0.017580\n",
       "V28       0.009536\n",
       "Amount    0.005632\n",
       "Class     1.000000\n",
       "Name: Class, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df.drop('Time', axis =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to imbalanced dataset we can reduce the split to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud = df[df['Class'] == 1]\n",
    "non_fraud = df[df['Class'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 30)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_fraud = non_fraud.sample(n = 1000)\n",
    "non_fraud.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fraud.append(non_fraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Class', axis = 1).values\n",
    "y = df['Class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    " X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model creatation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(29,activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(15,activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(units=1,activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=5, patience=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1119 samples, validate on 373 samples\n",
      "Epoch 1/600\n",
      "1119/1119 [==============================] - 1s 1ms/sample - loss: 0.6752 - val_loss: 0.6490\n",
      "Epoch 2/600\n",
      "1119/1119 [==============================] - 0s 37us/sample - loss: 0.6600 - val_loss: 0.6387\n",
      "Epoch 3/600\n",
      "1119/1119 [==============================] - 0s 32us/sample - loss: 0.6451 - val_loss: 0.6234\n",
      "Epoch 4/600\n",
      "1119/1119 [==============================] - 0s 38us/sample - loss: 0.6435 - val_loss: 0.6139\n",
      "Epoch 5/600\n",
      "1119/1119 [==============================] - 0s 33us/sample - loss: 0.6296 - val_loss: 0.6064\n",
      "Epoch 6/600\n",
      "1119/1119 [==============================] - 0s 35us/sample - loss: 0.6321 - val_loss: 0.5975\n",
      "Epoch 7/600\n",
      "1119/1119 [==============================] - 0s 36us/sample - loss: 0.6115 - val_loss: 0.5894\n",
      "Epoch 8/600\n",
      "1119/1119 [==============================] - 0s 37us/sample - loss: 0.6063 - val_loss: 0.5672\n",
      "Epoch 9/600\n",
      "1119/1119 [==============================] - 0s 30us/sample - loss: 0.5860 - val_loss: 0.5407\n",
      "Epoch 10/600\n",
      "1119/1119 [==============================] - 0s 46us/sample - loss: 0.5661 - val_loss: 0.5232\n",
      "Epoch 11/600\n",
      "1119/1119 [==============================] - 0s 38us/sample - loss: 0.5404 - val_loss: 0.4800\n",
      "Epoch 12/600\n",
      "1119/1119 [==============================] - 0s 41us/sample - loss: 0.5184 - val_loss: 0.4412\n",
      "Epoch 13/600\n",
      "1119/1119 [==============================] - 0s 34us/sample - loss: 0.5103 - val_loss: 0.4117\n",
      "Epoch 14/600\n",
      "1119/1119 [==============================] - 0s 37us/sample - loss: 0.4836 - val_loss: 0.3878\n",
      "Epoch 15/600\n",
      "1119/1119 [==============================] - 0s 34us/sample - loss: 0.4542 - val_loss: 0.3594\n",
      "Epoch 16/600\n",
      "1119/1119 [==============================] - 0s 34us/sample - loss: 0.4249 - val_loss: 0.3342\n",
      "Epoch 17/600\n",
      "1119/1119 [==============================] - 0s 36us/sample - loss: 0.4031 - val_loss: 0.3097\n",
      "Epoch 18/600\n",
      "1119/1119 [==============================] - 0s 36us/sample - loss: 0.4025 - val_loss: 0.2918\n",
      "Epoch 19/600\n",
      "1119/1119 [==============================] - 0s 31us/sample - loss: 0.3884 - val_loss: 0.2829\n",
      "Epoch 20/600\n",
      "1119/1119 [==============================] - 0s 34us/sample - loss: 0.3663 - val_loss: 0.2702\n",
      "Epoch 21/600\n",
      "1119/1119 [==============================] - 0s 46us/sample - loss: 0.3484 - val_loss: 0.2493\n",
      "Epoch 22/600\n",
      "1119/1119 [==============================] - 0s 41us/sample - loss: 0.3207 - val_loss: 0.2354\n",
      "Epoch 23/600\n",
      "1119/1119 [==============================] - 0s 38us/sample - loss: 0.3253 - val_loss: 0.2233\n",
      "Epoch 24/600\n",
      "1119/1119 [==============================] - 0s 35us/sample - loss: 0.3152 - val_loss: 0.2176\n",
      "Epoch 25/600\n",
      "1119/1119 [==============================] - 0s 37us/sample - loss: 0.2935 - val_loss: 0.2062\n",
      "Epoch 26/600\n",
      "1119/1119 [==============================] - 0s 54us/sample - loss: 0.2879 - val_loss: 0.2004\n",
      "Epoch 27/600\n",
      "1119/1119 [==============================] - 0s 33us/sample - loss: 0.2798 - val_loss: 0.1932\n",
      "Epoch 28/600\n",
      "1119/1119 [==============================] - 0s 29us/sample - loss: 0.2792 - val_loss: 0.1918\n",
      "Epoch 29/600\n",
      "1119/1119 [==============================] - 0s 42us/sample - loss: 0.2679 - val_loss: 0.1886\n",
      "Epoch 30/600\n",
      "1119/1119 [==============================] - 0s 29us/sample - loss: 0.2784 - val_loss: 0.1839\n",
      "Epoch 31/600\n",
      "1119/1119 [==============================] - 0s 27us/sample - loss: 0.2646 - val_loss: 0.1794\n",
      "Epoch 32/600\n",
      "1119/1119 [==============================] - 0s 32us/sample - loss: 0.2413 - val_loss: 0.1749\n",
      "Epoch 33/600\n",
      "1119/1119 [==============================] - 0s 29us/sample - loss: 0.2341 - val_loss: 0.1687\n",
      "Epoch 34/600\n",
      "1119/1119 [==============================] - 0s 28us/sample - loss: 0.2394 - val_loss: 0.1691\n",
      "Epoch 35/600\n",
      "1119/1119 [==============================] - 0s 30us/sample - loss: 0.2321 - val_loss: 0.1641\n",
      "Epoch 36/600\n",
      "1119/1119 [==============================] - 0s 32us/sample - loss: 0.2591 - val_loss: 0.1733\n",
      "Epoch 37/600\n",
      "1119/1119 [==============================] - 0s 29us/sample - loss: 0.2309 - val_loss: 0.1637\n",
      "Epoch 38/600\n",
      "1119/1119 [==============================] - 0s 41us/sample - loss: 0.2354 - val_loss: 0.1610\n",
      "Epoch 39/600\n",
      "1119/1119 [==============================] - 0s 50us/sample - loss: 0.2348 - val_loss: 0.1597\n",
      "Epoch 40/600\n",
      "1119/1119 [==============================] - 0s 50us/sample - loss: 0.2318 - val_loss: 0.1611\n",
      "Epoch 41/600\n",
      "1119/1119 [==============================] - 0s 52us/sample - loss: 0.2374 - val_loss: 0.1573\n",
      "Epoch 42/600\n",
      "1119/1119 [==============================] - 0s 45us/sample - loss: 0.2182 - val_loss: 0.1548\n",
      "Epoch 43/600\n",
      "1119/1119 [==============================] - 0s 32us/sample - loss: 0.1995 - val_loss: 0.1576\n",
      "Epoch 44/600\n",
      "1119/1119 [==============================] - 0s 49us/sample - loss: 0.2077 - val_loss: 0.1505\n",
      "Epoch 45/600\n",
      "1119/1119 [==============================] - 0s 37us/sample - loss: 0.2267 - val_loss: 0.1500\n",
      "Epoch 46/600\n",
      "1119/1119 [==============================] - 0s 35us/sample - loss: 0.2254 - val_loss: 0.1538\n",
      "Epoch 47/600\n",
      "1119/1119 [==============================] - 0s 45us/sample - loss: 0.2197 - val_loss: 0.1543\n",
      "Epoch 48/600\n",
      "1119/1119 [==============================] - 0s 43us/sample - loss: 0.2281 - val_loss: 0.1527\n",
      "Epoch 49/600\n",
      "1119/1119 [==============================] - 0s 53us/sample - loss: 0.2196 - val_loss: 0.1534\n",
      "Epoch 50/600\n",
      "1119/1119 [==============================] - 0s 41us/sample - loss: 0.2056 - val_loss: 0.1502\n",
      "Epoch 51/600\n",
      "1119/1119 [==============================] - 0s 45us/sample - loss: 0.2147 - val_loss: 0.1511\n",
      "Epoch 52/600\n",
      "1119/1119 [==============================] - 0s 46us/sample - loss: 0.2065 - val_loss: 0.1494\n",
      "Epoch 53/600\n",
      "1119/1119 [==============================] - 0s 36us/sample - loss: 0.2187 - val_loss: 0.1496\n",
      "Epoch 54/600\n",
      "1119/1119 [==============================] - 0s 40us/sample - loss: 0.2314 - val_loss: 0.1536\n",
      "Epoch 55/600\n",
      "1119/1119 [==============================] - ETA: 0s - loss: 0.232 - 0s 34us/sample - loss: 0.2208 - val_loss: 0.1485\n",
      "Epoch 56/600\n",
      "1119/1119 [==============================] - 0s 43us/sample - loss: 0.2049 - val_loss: 0.1470\n",
      "Epoch 57/600\n",
      "1119/1119 [==============================] - 0s 44us/sample - loss: 0.2059 - val_loss: 0.1459\n",
      "Epoch 58/600\n",
      "1119/1119 [==============================] - 0s 42us/sample - loss: 0.2356 - val_loss: 0.1474\n",
      "Epoch 59/600\n",
      "1119/1119 [==============================] - 0s 34us/sample - loss: 0.2103 - val_loss: 0.1449\n",
      "Epoch 60/600\n",
      "1119/1119 [==============================] - 0s 36us/sample - loss: 0.2048 - val_loss: 0.1454\n",
      "Epoch 61/600\n",
      "1119/1119 [==============================] - 0s 24us/sample - loss: 0.2095 - val_loss: 0.1486\n",
      "Epoch 62/600\n",
      "1119/1119 [==============================] - 0s 29us/sample - loss: 0.2013 - val_loss: 0.1486\n",
      "Epoch 63/600\n",
      "1119/1119 [==============================] - 0s 29us/sample - loss: 0.2123 - val_loss: 0.1484\n",
      "Epoch 64/600\n",
      "1119/1119 [==============================] - 0s 28us/sample - loss: 0.1986 - val_loss: 0.1483\n",
      "Epoch 65/600\n",
      "1119/1119 [==============================] - 0s 34us/sample - loss: 0.2178 - val_loss: 0.1462\n",
      "Epoch 66/600\n",
      "1119/1119 [==============================] - 0s 34us/sample - loss: 0.2080 - val_loss: 0.1454\n",
      "Epoch 67/600\n",
      "1119/1119 [==============================] - 0s 29us/sample - loss: 0.2029 - val_loss: 0.1441\n",
      "Epoch 68/600\n",
      "1119/1119 [==============================] - 0s 28us/sample - loss: 0.2049 - val_loss: 0.1446\n",
      "Epoch 69/600\n",
      "1119/1119 [==============================] - 0s 33us/sample - loss: 0.2047 - val_loss: 0.1443\n",
      "Epoch 70/600\n",
      "1119/1119 [==============================] - 0s 36us/sample - loss: 0.2051 - val_loss: 0.1428\n",
      "Epoch 71/600\n",
      "1119/1119 [==============================] - 0s 35us/sample - loss: 0.2074 - val_loss: 0.1453\n",
      "Epoch 72/600\n",
      "1119/1119 [==============================] - 0s 31us/sample - loss: 0.2158 - val_loss: 0.1431\n",
      "Epoch 73/600\n",
      "1119/1119 [==============================] - 0s 27us/sample - loss: 0.2100 - val_loss: 0.1404\n",
      "Epoch 74/600\n",
      "1119/1119 [==============================] - 0s 26us/sample - loss: 0.1982 - val_loss: 0.1406\n",
      "Epoch 75/600\n",
      "1119/1119 [==============================] - 0s 24us/sample - loss: 0.2047 - val_loss: 0.1404\n",
      "Epoch 76/600\n",
      "1119/1119 [==============================] - 0s 25us/sample - loss: 0.2025 - val_loss: 0.1432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/600\n",
      "1119/1119 [==============================] - 0s 23us/sample - loss: 0.1830 - val_loss: 0.1428\n",
      "Epoch 78/600\n",
      "1119/1119 [==============================] - 0s 25us/sample - loss: 0.2124 - val_loss: 0.1428\n",
      "Epoch 79/600\n",
      "1119/1119 [==============================] - 0s 25us/sample - loss: 0.1970 - val_loss: 0.1413\n",
      "Epoch 80/600\n",
      "1119/1119 [==============================] - 0s 26us/sample - loss: 0.1959 - val_loss: 0.1420\n",
      "Epoch 81/600\n",
      "1119/1119 [==============================] - 0s 25us/sample - loss: 0.1956 - val_loss: 0.1420\n",
      "Epoch 82/600\n",
      "1119/1119 [==============================] - 0s 40us/sample - loss: 0.2181 - val_loss: 0.1410\n",
      "Epoch 83/600\n",
      "1119/1119 [==============================] - 0s 29us/sample - loss: 0.2018 - val_loss: 0.1406\n",
      "Epoch 84/600\n",
      "1119/1119 [==============================] - 0s 34us/sample - loss: 0.1960 - val_loss: 0.1375\n",
      "Epoch 85/600\n",
      "1119/1119 [==============================] - 0s 30us/sample - loss: 0.2230 - val_loss: 0.1394\n",
      "Epoch 86/600\n",
      "1119/1119 [==============================] - 0s 37us/sample - loss: 0.2029 - val_loss: 0.1415\n",
      "Epoch 87/600\n",
      "1119/1119 [==============================] - 0s 28us/sample - loss: 0.1872 - val_loss: 0.1425\n",
      "Epoch 88/600\n",
      "1119/1119 [==============================] - 0s 29us/sample - loss: 0.1854 - val_loss: 0.1396\n",
      "Epoch 89/600\n",
      "1119/1119 [==============================] - 0s 25us/sample - loss: 0.1890 - val_loss: 0.1401\n",
      "Epoch 90/600\n",
      "1119/1119 [==============================] - 0s 27us/sample - loss: 0.2136 - val_loss: 0.1414\n",
      "Epoch 91/600\n",
      "1119/1119 [==============================] - 0s 26us/sample - loss: 0.2118 - val_loss: 0.1422\n",
      "Epoch 92/600\n",
      "1119/1119 [==============================] - 0s 29us/sample - loss: 0.1979 - val_loss: 0.1426\n",
      "Epoch 93/600\n",
      "1119/1119 [==============================] - 0s 28us/sample - loss: 0.2110 - val_loss: 0.1420\n",
      "Epoch 94/600\n",
      "1119/1119 [==============================] - 0s 27us/sample - loss: 0.2101 - val_loss: 0.1382\n",
      "Epoch 95/600\n",
      "1119/1119 [==============================] - 0s 25us/sample - loss: 0.2016 - val_loss: 0.1387\n",
      "Epoch 96/600\n",
      "1119/1119 [==============================] - 0s 27us/sample - loss: 0.2042 - val_loss: 0.1420\n",
      "Epoch 97/600\n",
      "1119/1119 [==============================] - 0s 28us/sample - loss: 0.1903 - val_loss: 0.1381\n",
      "Epoch 98/600\n",
      "1119/1119 [==============================] - 0s 24us/sample - loss: 0.1924 - val_loss: 0.1368\n",
      "Epoch 99/600\n",
      "1119/1119 [==============================] - 0s 24us/sample - loss: 0.2078 - val_loss: 0.1373\n",
      "Epoch 100/600\n",
      "1119/1119 [==============================] - 0s 26us/sample - loss: 0.1946 - val_loss: 0.1384\n",
      "Epoch 101/600\n",
      "1119/1119 [==============================] - 0s 29us/sample - loss: 0.2008 - val_loss: 0.1390\n",
      "Epoch 102/600\n",
      "1119/1119 [==============================] - 0s 26us/sample - loss: 0.2017 - val_loss: 0.1404\n",
      "Epoch 103/600\n",
      "1119/1119 [==============================] - 0s 28us/sample - loss: 0.1902 - val_loss: 0.1399\n",
      "Epoch 104/600\n",
      "1119/1119 [==============================] - 0s 29us/sample - loss: 0.1931 - val_loss: 0.1388\n",
      "Epoch 105/600\n",
      "1119/1119 [==============================] - 0s 25us/sample - loss: 0.1867 - val_loss: 0.1386\n",
      "Epoch 106/600\n",
      "1119/1119 [==============================] - 0s 26us/sample - loss: 0.1746 - val_loss: 0.1373\n",
      "Epoch 107/600\n",
      "1119/1119 [==============================] - 0s 27us/sample - loss: 0.1947 - val_loss: 0.1367\n",
      "Epoch 108/600\n",
      "1119/1119 [==============================] - 0s 26us/sample - loss: 0.1985 - val_loss: 0.1383\n",
      "Epoch 109/600\n",
      "1119/1119 [==============================] - 0s 28us/sample - loss: 0.1948 - val_loss: 0.1378\n",
      "Epoch 110/600\n",
      "1119/1119 [==============================] - 0s 26us/sample - loss: 0.1992 - val_loss: 0.1378\n",
      "Epoch 111/600\n",
      "1119/1119 [==============================] - 0s 25us/sample - loss: 0.1940 - val_loss: 0.1364\n",
      "Epoch 112/600\n",
      "1119/1119 [==============================] - 0s 27us/sample - loss: 0.1996 - val_loss: 0.1366\n",
      "Epoch 113/600\n",
      "1119/1119 [==============================] - 0s 23us/sample - loss: 0.1798 - val_loss: 0.1346\n",
      "Epoch 114/600\n",
      "1119/1119 [==============================] - 0s 25us/sample - loss: 0.1955 - val_loss: 0.1338\n",
      "Epoch 115/600\n",
      "1119/1119 [==============================] - 0s 30us/sample - loss: 0.1901 - val_loss: 0.1336\n",
      "Epoch 116/600\n",
      "1119/1119 [==============================] - 0s 27us/sample - loss: 0.1842 - val_loss: 0.1335\n",
      "Epoch 117/600\n",
      "1119/1119 [==============================] - 0s 22us/sample - loss: 0.1822 - val_loss: 0.1339\n",
      "Epoch 118/600\n",
      "1119/1119 [==============================] - 0s 25us/sample - loss: 0.1966 - val_loss: 0.1346\n",
      "Epoch 119/600\n",
      "1119/1119 [==============================] - 0s 23us/sample - loss: 0.1846 - val_loss: 0.1436\n",
      "Epoch 120/600\n",
      "1119/1119 [==============================] - 0s 25us/sample - loss: 0.1930 - val_loss: 0.1359\n",
      "Epoch 121/600\n",
      "1119/1119 [==============================] - 0s 25us/sample - loss: 0.1854 - val_loss: 0.1444\n",
      "Epoch 122/600\n",
      "1119/1119 [==============================] - 0s 24us/sample - loss: 0.1805 - val_loss: 0.1349\n",
      "Epoch 123/600\n",
      "1119/1119 [==============================] - 0s 22us/sample - loss: 0.1766 - val_loss: 0.1354\n",
      "Epoch 124/600\n",
      "1119/1119 [==============================] - 0s 21us/sample - loss: 0.1895 - val_loss: 0.1346\n",
      "Epoch 125/600\n",
      "1119/1119 [==============================] - 0s 26us/sample - loss: 0.1822 - val_loss: 0.1329\n",
      "Epoch 126/600\n",
      "1119/1119 [==============================] - 0s 27us/sample - loss: 0.1830 - val_loss: 0.1323\n",
      "Epoch 127/600\n",
      "1119/1119 [==============================] - 0s 32us/sample - loss: 0.1955 - val_loss: 0.1337\n",
      "Epoch 128/600\n",
      "1119/1119 [==============================] - 0s 26us/sample - loss: 0.2085 - val_loss: 0.1363\n",
      "Epoch 129/600\n",
      "1119/1119 [==============================] - 0s 25us/sample - loss: 0.2030 - val_loss: 0.1377\n",
      "Epoch 130/600\n",
      "1119/1119 [==============================] - 0s 26us/sample - loss: 0.1987 - val_loss: 0.1363\n",
      "Epoch 131/600\n",
      "1119/1119 [==============================] - 0s 27us/sample - loss: 0.1848 - val_loss: 0.1343\n",
      "Epoch 132/600\n",
      "1119/1119 [==============================] - 0s 26us/sample - loss: 0.1833 - val_loss: 0.1355\n",
      "Epoch 133/600\n",
      "1119/1119 [==============================] - 0s 26us/sample - loss: 0.1917 - val_loss: 0.1342\n",
      "Epoch 134/600\n",
      "1119/1119 [==============================] - 0s 26us/sample - loss: 0.1920 - val_loss: 0.1337\n",
      "Epoch 135/600\n",
      "1119/1119 [==============================] - 0s 24us/sample - loss: 0.1869 - val_loss: 0.1349\n",
      "Epoch 136/600\n",
      "1119/1119 [==============================] - 0s 25us/sample - loss: 0.1981 - val_loss: 0.1370\n",
      "Epoch 137/600\n",
      "1119/1119 [==============================] - 0s 21us/sample - loss: 0.1741 - val_loss: 0.1338\n",
      "Epoch 138/600\n",
      "1119/1119 [==============================] - 0s 29us/sample - loss: 0.1741 - val_loss: 0.1325\n",
      "Epoch 139/600\n",
      "1119/1119 [==============================] - 0s 25us/sample - loss: 0.1931 - val_loss: 0.1331\n",
      "Epoch 140/600\n",
      "1119/1119 [==============================] - 0s 28us/sample - loss: 0.1991 - val_loss: 0.1358\n",
      "Epoch 141/600\n",
      "1119/1119 [==============================] - 0s 28us/sample - loss: 0.1922 - val_loss: 0.1364\n",
      "Epoch 142/600\n",
      "1119/1119 [==============================] - 0s 29us/sample - loss: 0.1921 - val_loss: 0.1367\n",
      "Epoch 143/600\n",
      "1119/1119 [==============================] - 0s 28us/sample - loss: 0.1847 - val_loss: 0.1360\n",
      "Epoch 144/600\n",
      "1119/1119 [==============================] - 0s 24us/sample - loss: 0.1921 - val_loss: 0.1376\n",
      "Epoch 145/600\n",
      "1119/1119 [==============================] - 0s 26us/sample - loss: 0.1746 - val_loss: 0.1367\n",
      "Epoch 146/600\n",
      "1119/1119 [==============================] - 0s 24us/sample - loss: 0.1778 - val_loss: 0.1360\n",
      "Epoch 147/600\n",
      "1119/1119 [==============================] - 0s 23us/sample - loss: 0.1695 - val_loss: 0.1357\n",
      "Epoch 148/600\n",
      "1119/1119 [==============================] - 0s 24us/sample - loss: 0.1735 - val_loss: 0.1394\n",
      "Epoch 149/600\n",
      "1119/1119 [==============================] - 0s 25us/sample - loss: 0.1766 - val_loss: 0.1338\n",
      "Epoch 150/600\n",
      "1119/1119 [==============================] - 0s 26us/sample - loss: 0.1827 - val_loss: 0.1350\n",
      "Epoch 151/600\n",
      "1119/1119 [==============================] - 0s 24us/sample - loss: 0.1851 - val_loss: 0.1355\n",
      "Epoch 152/600\n",
      "1119/1119 [==============================] - 0s 23us/sample - loss: 0.1905 - val_loss: 0.1385\n",
      "Epoch 153/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1119/1119 [==============================] - 0s 23us/sample - loss: 0.1758 - val_loss: 0.1372\n",
      "Epoch 154/600\n",
      "1119/1119 [==============================] - 0s 24us/sample - loss: 0.1804 - val_loss: 0.1395\n",
      "Epoch 155/600\n",
      "1119/1119 [==============================] - 0s 24us/sample - loss: 0.1721 - val_loss: 0.1347\n",
      "Epoch 156/600\n",
      "1119/1119 [==============================] - 0s 23us/sample - loss: 0.1941 - val_loss: 0.1338\n",
      "Epoch 157/600\n",
      "1119/1119 [==============================] - 0s 23us/sample - loss: 0.1720 - val_loss: 0.1374\n",
      "Epoch 158/600\n",
      "1119/1119 [==============================] - 0s 24us/sample - loss: 0.1875 - val_loss: 0.1355\n",
      "Epoch 159/600\n",
      "1119/1119 [==============================] - 0s 24us/sample - loss: 0.1737 - val_loss: 0.1334\n",
      "Epoch 160/600\n",
      "1119/1119 [==============================] - 0s 24us/sample - loss: 0.1790 - val_loss: 0.1331\n",
      "Epoch 161/600\n",
      "1119/1119 [==============================] - 0s 23us/sample - loss: 0.1955 - val_loss: 0.1339\n",
      "Epoch 00161: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20c22d10c50>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, \n",
    "          y=y_train, \n",
    "          epochs=600,\n",
    "          batch_size= 128,\n",
    "          validation_data=(X_test, y_test), verbose=1,\n",
    "          callbacks=[early_stop]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x20c22e89cf8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD7CAYAAACG50QgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nOzdd3xV5f3A8c9zb/YmEzJJCJsww96IitaCq4J722oVf7ZatVZbrbWtVm2tWCduBMRRVAoqsneABAgQyCBkELII2fM+vz9OCAlk3MAllyTf9+uV180959xzv/cGvuc5z1Raa4QQQnQPJnsHIIQQouNI0hdCiG5Ekr4QQnQjkvSFEKIbkaQvhBDdiCR9IYToRqxK+kqpWUqpJKVUslLqiWb2v6qUiq//OaSUKrJ9qEIIIc6XaqufvlLKDBwCLgUygR3AjVrr/S0c/xAwQmt9l41jFUIIcZ4crDhmDJCstU4FUEotBuYAzSZ94Ebgj22d1N/fX/fu3dvKMIUQQgDs3LkzX2sdcK6vtybphwAZjZ5nAmObO1ApFQFEAj+1sP8+4D6A8PBw4uLi2hWsEEJ0d0qp9PN5vTV1+qqZbS3VCc0Dlmmt65rbqbV+W2sdq7WODQg45wuVEEKIc2RN0s8Ewho9DwWyWzh2HvDZ+QYlhBDiwrAm6e8A+iqlIpVSThiJffmZByml+gM9gC22DVEIIYSttFmnr7WuVUo9CKwCzMBCrXWiUuo5IE5rfeoCcCOwWMu0nUKIVtTU1JCZmUllZaW9Q7moubi4EBoaiqOjo03P22aXzQslNjZWS0OuEN1PWloanp6e+Pn5oVRzTYZCa01BQQElJSVERkY22aeU2qm1jj3Xc8uIXCFEh6qsrJSE3walFH5+fhfkbkiSvhCiw0nCb9uF+o7slvQLyqrt9dZCCNFt2S3p55yspKK62e78QghxQXl4eNg7BLuxW9K3aM2qxBx7vb0QQnRLdkv6TmYTn+/MaPtAIYS4QLTWPPbYYwwZMoSYmBiWLFkCwLFjx5gyZQrDhw9nyJAhbNiwgbq6Ou64446GY1999VU7R39urJl754Lo4e7EpuQCMgrLCfN1s1cYQgg7evabRPZnF9v0nIOCvfjjzwdbdeyXX35JfHw8CQkJ5OfnM3r0aKZMmcKiRYu4/PLLeeqpp6irq6O8vJz4+HiysrLYt28fAEVFnXMGebuV9Hu4OaIULNuZaa8QhBDd3MaNG7nxxhsxm80EBQUxdepUduzYwejRo3n//ff505/+xN69e/H09CQqKorU1FQeeughVq5ciZeXl73DPyd2K+k7mk1MivZn2c5MHr6kLyaTdOESoruxtkR+obQ0OHXKlCmsX7+e7777jltvvZXHHnuM2267jYSEBFatWsWCBQtYunQpCxcu7OCIz59d++n/IjaMrKIKtqQW2DMMIUQ3NWXKFJYsWUJdXR15eXmsX7+eMWPGkJ6eTmBgIPfeey933303u3btIj8/H4vFwnXXXcef//xndu3aZe/wz4ndSvoAlw0KwsvFgaVxGUyM9rdnKEKIbuiaa65hy5YtDBs2DKUUL774Ij179uTDDz/kpZdewtHREQ8PDz766COysrK48847sVgsAPz1r3+1c/Tnxn5z74waoeN27ubpr/exNC6D7U/NxNvVthMLCSEuPgcOHGDgwIH2DqNTaO676rxz7xSkgtbcEBtGVa2FbxJamqJfCCGErdgv6VeXwoHlDAnxYkBPTz7acoSd6SeorbPYLSQhhOjq7Jf0HVzhhz+i6mq4f1ofknNLue4/m5n60loKZV4eIYS4IOyX9L2D4UQaxL3HnOEh7Hr6Ul66fihZRRV8HicjdYUQ4kKwX9J39oKoabD+JaitwsfNiV/EhjGmty+Lth/FYpEFuIQQwtbsO5/++AehvAAOrWzYdPO4cNILytmQnG/HwIQQomuyb9LvMwM8e0H8ooZNs4b0xN/DiYUb0/hgUxq3vreNzBPldgxSCCG6DvsmfZMZhs6Fwz9AyXEAnB3M3BAbxrpDefzpm/1sOJzPf+OlO6cQwj5am3v/yJEjDBkypAOjOX/2Xy5x+M2g62Dv0oZN90yO4pdTovji/gkM7OXFukN5dgxQCCG6DrtOwwBAQD8IHQ27PzHq+JXC192JJ680RqFN7RfAuxtSKamswdNFRuwK0aX87wnI2Wvbc/aMgSv+1uLuxx9/nIiICB544AEA/vSnP6GUYv369Zw4cYKamhqef/555syZ0663rays5P777ycuLg4HBwdeeeUVpk+fTmJiInfeeSfV1dVYLBa++OILgoODueGGG8jMzKSuro6nn36auXPnntfHtpb9S/oAsXdD3kFIWHzWrin9/Km1aLakyKRsQojzN2/evIbFUgCWLl3KnXfeyVdffcWuXbtYs2YNv/3tb1ucgbMlCxYsAGDv3r189tln3H777VRWVvLmm2/y8MMPEx8fT1xcHKGhoaxcuZLg4GASEhLYt28fs2bNsulnbI39S/pg1OvHvQc/PA39rwBXn4ZdsRG+uDmZWX84j8sG97RjkEIIm2ulRH6hjBgxgtzcXLKzs8nLy6NHjx706tWLRx55hPXr12MymcjKyuL48eP07Gl9ztm4cSMPPfQQAAMGDCAiIoJDhw4xfvx4/vKXv5CZmcm1115L3759iYmJ4dFHH+Xxxx/nqquuYvLkyRfq457l4ijpm0zws5eN7ps/Pd9kl5ODifFRfqw/JF04hRC2cf3117Ns2TKWLFnCvHnz+PTTT8nLy2Pnzp3Ex8cTFBREZWVlu87Z0p3BTTfdxPLly3F1deXyyy/np59+ol+/fuzcuZOYmBiefPJJnnvuOVt8LKtcHEkfoNcwGH2vUeJPW99k15R+ARwtLOdIfpmdghNCdCXz5s1j8eLFLFu2jOuvv56TJ08SGBiIo6Mja9asIT09vd3nnDJlCp9++ikAhw4d4ujRo/Tv35/U1FSioqKYP38+s2fPZs+ePWRnZ+Pm5sYtt9zCo48+2qFz8188SR/gkmfALxqW3Q0lOQ2bp/cPRCl44ss9FFfW2DFAIURXMHjwYEpKSggJCaFXr17cfPPNxMXFERsby6effsqAAQPafc4HHniAuro6YmJimDt3Lh988AHOzs4sWbKEIUOGMHz4cA4ePMhtt93G3r17GTNmDMOHD+cvf/kLf/jDHy7Ap2ye/ebTj43VcXFxZ+/IPQDvzIDgEXDbcjAbzQ5f787i0c8TiA704OO7xxLg6dzBEQshbEHm07ee3ebTV0rNUkolKaWSlVJPtHDMDUqp/UqpRKXUouaOsUrgQLjqVUjfBFsXNGy+ekQI7985mpS8Ut5al3LOpxdCiO6szd47SikzsAC4FMgEdiillmut9zc6pi/wJDBRa31CKRV4XlENnQsHvoE1L8CAq8CvDwCT+wYwLsqPtYfy6LibISFEd7d3715uvfXWJtucnZ3Ztm2bnSI6d9Z02RwDJGutUwGUUouBOcD+RsfcCyzQWp8A0FrnnldUSsGV/4AFY+Gbh+H2b4xtGIO1nv/uAJknygnt4XZebyOEsA+tNar+/3RnEBMTQ3x8fIe+54WqeremeicEaDzBfWb9tsb6Af2UUpuUUluVUs2ONFBK3aeUilNKxeXltTG1glcvuOw5OLIBdrzbsHlaf+MmYm2STM0gRGfk4uJCQUHBBUtqXYHWmoKCAlxcXGx+bmtK+s1djs/8azkAfYFpQCiwQSk1RGtd1ORFWr8NvA1GQ26b7zzydjjwLXz/B+g9CQIH0ifAndAerqxNyuOWcRFWhC+EuJiEhoaSmZlJmwW/bs7FxYXQ0FCbn9eapJ8JhDV6HgqcOe1lJrBVa10DpCmlkjAuAjvOKzql4Oo34I3x8MU9cM9qlKML0/oH8OWuLKpq63B2MJ/XWwghOpajoyORkZH2DqPbsqZ6ZwfQVykVqZRyAuYBy8845mtgOoBSyh+juifVJhF6BMKcBXB8HyR8Bhj99sur69iRdsImbyGEEN1Fm0lfa10LPAisAg4AS7XWiUqp55RSs+sPWwUUKKX2A2uAx7TWtpshrd/l4BUCqWsBGN/HDyezibVJ59deLIQQ3Y1VE65prVcAK87Y9kyj3zXwm/of21MKIqfAoVVgseDm5MDYKF/puimEEO10cU3D0JrIqVBRCLmJgNF1Mzm3VJZSFEKIduhESb9+6tH6ydik66YQQrRf50n63qHg2wdS1wE06bophBDCOp0n6QNETTXm5KmrQSnFtP4BbE7Jp6q2zt6RCSFEp9C5kn7kFKguhezdAEzrZ3TdjDsiXTeFEMIanSvp955iPB7ZAMCEaKPr5pqD0nVTCCGs0bmSvrsf+PWFTGMefjcnB0aE+7DjSKGdAxNCiM6hcyV9gNBYyNwB9ZM1jYzoQWJ2MZU1Uq8vhBBt6ZxJvywPio4CMCq8B7UWzZ7Mk3YOTAghLn6dL+mH1K8SlmnM5TYi3AeAXUelMVcIIdrS+ZJ+0GBwcIGsnQD4eTjT28+NXemS9IUQoi2dL+mbHY1F0zNPL6o+MrwHu46ekEUZhBCiDZ0v6QOEjIJjCVBbDcCIiB7kl1aTUVhh58CEEOLi1jmTfuhoqKuC43sBGCn1+kIIYZVOmvRPNeYaVTz9gzxxdzJL0hdCiDZ0zqTvFQLe4ZDyEwAOZhPDw33YniaDtIQQojWdM+krBQOvMpJ+ZTEAE/r4czCnhPzSKjsHJ4QQF6/OmfQBBs2BumpjNS1gQh8/ALak2G6VRiGE6Go6b9IPHQMePWH/1wDEhHjj6ezA5pR8OwcmhBAXr86b9E0mGDQbkn+EqlIczCbGRvmxKVlK+kII0ZLOm/TBqOKprYTD3wMwMdqPo4XlZBTKurlCCNGczp30w8eDm39Dvf7EaH8AqeIRQogWdO6kbzIbc/EUJAPQN9CDAE9nqeIRQogWdO6kD9CjN5w4AoBSiun9A1iVmMOh4yV2DUsIIS5GnT/p+0ZCeT5UGUn+0cv74+7swMOL42XBdCGEOEPnT/o9ehuP9aX9QE8XXrxuKAeOFfPy94fsFpYQQlyMulzSB5g5KIhrR4bwwaYjUtoXQohGrEr6SqlZSqkkpVSyUuqJZvbfoZTKU0rF1//cY/tQW9BM0ge4dGAQ1XUWDhyTun0hhDilzaSvlDIDC4ArgEHAjUqpQc0cukRrPbz+510bx9ky1x7g4n1W0h9eP93ybpl5UwghGlhT0h8DJGutU7XW1cBiYM6FDaudGvXgOaWXtytBXs7EZxTZJSQhhLgYWZP0Q4CMRs8z67ed6Tql1B6l1DKlVFhzJ1JK3aeUilNKxeXl5Z1DuC1oJukDDA/zkaQvhBCNWJP0VTPbzlyM9hugt9Z6KPAj8GFzJ9Jav621jtVaxwYEBLQv0tb06A1FR8HStNF2eFgP0gvKKSyrtt17CSFEJ2ZN0s8EGpfcQ4HsxgdorQu01qcmsn8HGGWb8KzUo7cxzXLJsSabR9TX6ydIaV8IIQDrkv4OoK9SKlIp5QTMA5Y3PkAp1avR09nAAduFaIUWevDEhHhjUrBbkr4QQgBWJH2tdS3wILAKI5kv1VonKqWeU0rNrj9svlIqUSmVAMwH7rhQATerhaTv7uxAvyBP6cEjhBD1HKw5SGu9AlhxxrZnGv3+JPCkbUNrB+8wUOZmG3NHhPvw3Z5jWCwak6m55gkhhOg+Ov+IXACzI3iHNpv0h4X6UFxZS8YJmWNfCCG6RtIHo4qnMPWszUNCvAHYl1XcwQEJIcTFp+skfb9oY1593bQ3ad8gDxzNin3ZJ+0UmBBCXDy6VtKvPAnlhU02OzuY6Rfkyb4sSfpCCNGFkn4f47F+Fa3GhgR7sy/rJFqfOaZMCCG6ly6U9KONx+aSfogXJ8pryD5Z2cFBCSHExaXrJH2fcDA5NJv0Bzc05koVjxCie+s6Sd/sWN+DJ+WsXQN7emFSkChJXwjRzXWdpA/1PXjOTvquTmb6BnqyL1u6bQohureumfQtlrN2DQ7xkuodIUS318WSfh+orYCS7LN2DQn2JrekitxiacwVQnRfXSvp+7bSbfNUY64M0hJCdGNdK+m30m1zULAXINMxCCG6t66V9D17gaNbs425Hs4ORPm7S72+EKJb61pJ32QyqniaKemD0V8/UXrwCCG6sa6V9AH8oyEvqdldQ4K9yCqqkDVzhRDdVtdL+j1joCgdKs5eIvFUY26iNOYKIbqprpf0ew0zHnP2nrVrsDTmCiG6ua6X9HvWJ/1jCWft8nFzIrSHq3TbFEJ0W10v6XsEgFdIs0kfICbEW+bgEUJ0W10v6YNRxdNC0h8S4s2RgnKKK2s6OCghhLC/rpv08w9BddlZu0415sYfPbuhVwghurqum/TRkLPvrF2xET1wMCk2pxR0fFxCCGFnXTjp02wVj7uzAyPCfdiUnN/BQQkhhP11zaTv2QvcA1qs158Y7c++7JMUlcsgLSFE99I1k75SrTbmToz2R2vYmipVPEKI7qVrJn2A4BGQux+qSs/aNSzUBzcnMxulikcI0c1YlfSVUrOUUklKqWSl1BOtHHe9UkorpWJtF+I5Ch8Pug4yt5+1y8nBxNhIXzYnS0lfCNG9tJn0lVJmYAFwBTAIuFEpNaiZ4zyB+cA2Wwd5TsLGgDJD+uZmd0+M9ic1v4wvdmayN1MGawkhugdrSvpjgGStdarWuhpYDMxp5rg/Ay8CF8d6hM6e0GsopG9pdvf0AYE4mBS//TyBn7++kU+2pndwgEII0fGsSfohQEaj55n12xoopUYAYVrrb1s7kVLqPqVUnFIqLi8vr93BtlvERMjcAbVVZ+3qE+DBzqcvZcX8ycSEeLNwUxpa6wsfkxBC2JE1SV81s60hOyqlTMCrwG/bOpHW+m2tdazWOjYgIMD6KM9V+Hioq4Ls3c3u9nZ1ZFCwF7dP6E1qXhlbUwsvfExCCGFH1iT9TCCs0fNQILvRc09gCLBWKXUEGAcsv2gacwHSN7V62FVDe+Hl4sCn26SKRwjRtVmT9HcAfZVSkUopJ2AesPzUTq31Sa21v9a6t9a6N7AVmK21jrsgEbeHux8EDGixXv8UF0cz148KY1ViDnklZ1cFCSFEV9Fm0tda1wIPAquAA8BSrXWiUuo5pdTsCx3geYuYAEe3gqWu1cNuHhdOTZ3m691ZHRSYEEJ0PKv66WutV2it+2mt+2it/1K/7Rmt9fJmjp12UZTyTwkdA9UlkH+41cP6BHjQL8iD9Yc7oIFZCCHspOuOyD0leITx2EJjbmMT+viz40ghVbWt3xUIIURn1fWTvn9fcHSHY/FtHjox2p/KGgu7Za59IUQX1fWTvslsDNKyoqQ/NsoXk4LNMiePEKKL6vpJH4wqnmN7oK621cO8XBwZGurDJllgRQjRRXWfpF9bYSyh2IYJffxIyCiitKr1C4QQQnRG3SPp9xpuPFpRxTMx2p9ai2Z7mpT2hRBdT/dI+n7R4ORhVdIfFdEDJwcTGw5Lvb4QouvpHknfZDJK+1b04HFxNDMp2p/vE4/LBGxCiC6neyR9gODhkLMX6mraPHTW4J5kFVWQmF3cAYEJIUTH6UZJfwTUVsLxxDYPnTkoCLNJsXJfTgcEJoQQHaf7JP3wccZjRtsLe/m6OzE20peViZL0hRBdS/dJ+t6h4BUKR1ufcfOUWUN6kpxbSnJuyQUOTAghOk73SfpglPaPbgMrGmgvG9QTQKp4hBBdSvdL+iXZcDKjzUN7ersQE+LNRpmSQQjRhXSvpB821ng8utWqw4eH+bAvqxiLRbpuCiG6hu6V9IMGg5On1Ul/aKg3pVW1pOaXXuDAhBCiY3SvpG8yQ9hoq3rwAAwL8wEgIePkhYxKCCE6TPdK+gBh44y++pVtJ/I+AR64OZlJyJT59YUQXUP3S/rhYwENGTvaPNRsUgwJ8SYhU0r6Qoiuofsl/ZBYUGbIsK5ef1ioNweyi6mutVzgwIQQ4sLrfknf2QN6xrSjMdeH6joLSTklaK1l/VwhRKfW/ZI+GP31s3ZaNfnasFCjMXdl4jFmv76Jn722kcoaSfxCiM6peyb9sLFQUw45e9o+1NeVHm6OLFiTUj8tQykfbD5y4WMUQogLoHsm/VOTrx1tu+umUorp/QOJDvTgm4cmMnNgIK//lExeSdUFDlIIIWyveyZ9r2DwCbe6MfcfvxjGD49MITrQk99fOZDKmjpe+SHpAgcphBC21z2TPhj99Y9utWryNZNJoZQCICrAgxvHhPN5XCZlsni6EKKT6b5JP3wslB6HE0fa/dJZQ3rWL55eaPu4hBDiAuq+ST9iovGYurbdLx0V0QNnB5PMwCmE6HSsSvpKqVlKqSSlVLJS6olm9v9KKbVXKRWvlNqolBpk+1BtLGAA+EbBgW/a/VIXRzOje/uySZK+EKKTaTPpK6XMwALgCmAQcGMzSX2R1jpGaz0ceBF4xeaR2ppSMPDnkLYOKto/t86EaD8O5pRILx4hRKdiTUl/DJCstU7VWlcDi4E5jQ/QWhc3euoOdI4J6AfOBkstHFrV7pdOivYHYHOKlPaFEJ2HNUk/BGi81FRm/bYmlFK/VkqlYJT05zd3IqXUfUqpOKVUXF5e3rnEa1vBI8EzGA4sb/dLBwd74+3qKFU8QohOxZqkr5rZdlZJXmu9QGvdB3gc+ENzJ9Jav621jtVaxwYEBLQv0gvBZIKBV0Hyaqgua9dLzSbF+Cg/Nh7Op05W1hJCdBLWJP1MIKzR81Agu5XjFwNXn09QHWrgz6G24pwadK8c2ovsk5U8+nkCtXUyC6cQ4uJnTdLfAfRVSkUqpZyAeUCT+hClVN9GT38GHLZdiBdYxERj1s0fnoGKE+166exhwTx6WT++2p3FI0sTpMQvhLjotZn0tda1wIPAKuAAsFRrnaiUek4pNbv+sAeVUolKqXjgN8DtFyxiWzOZYfbrUJYP3z/d7pc/OKMvv5vVn28SsnlrfcoFCFAIIWzHwZqDtNYrgBVnbHum0e8P2ziujhU8HCY8CJv+BUNvgMgp7Xr5/VP7kJhVzCvfH2JiH/+GtXWFEOJi031H5J5p2pPgFQpr/97ulyqleOGaGAI9nZm/eDcLN6axJikXbcW8PkII0ZEk6Z/i6Arj7of0jZC1q90v93Zz5J/zRlBUXsNz3+7nzvd3sHDTEQCKK2uY/OJPfCjz8Ash7EySfmMjbwNnL9jy+jm9fEykL/HPXMrOP8xkfJQf/1mbTHl1LW+uTSGjsIK316dKY68Qwq4k6Tfm4gWjbofEr+FE+jmdQimFn4czj17ej/zSal5cmcR7G9OI8HMjq6iCnw7m2jhoIYSwniT9M439lTEvT9x753WaURG+TO0XwAebj6A1fHTXGHp6ufDRliM2CVMIIc6FJP0zeYdC70lw+IfzPtVvLu0HwB0TexPh585NY8PZcDiftPz2jf4VQghbkaTfnD4zIHc/FLc28Lhtw8J8WDF/Mo9d3h+AeaPDcDApFu84aosohRCi3STpN6fPJcZjyprzPtWgYC8czcbXHOjlwujevmw8LJO0CSHsQ5J+c4IGg0cQpKy2+anHRvmy/1gxJytqWj3ux/3HueTltVRU19k8BiFE9yVJvzlKGVU8KWvAYtukOzbSD60h7kjr6+uuSswhJa+M/cdO2vT9hRDdmyT9lvSZARWFcCzBpqcdEe6Dk9nE1tSCVo9LyDRW89qTKUlfCGE7kvRbEjXdeLRxFY+Lo5nh4T5sS2u5pF9SWcPh3FIA9krSF0LYkCT9lngEGCtrJX4NNp5DZ1ykL/uyTlJS2Xy9/t6sk2gNXi4O7MmSpC+EsB1J+q0ZeSsc3wcZ22162rFRflg0xKU3P39/fIZRtXP9qDBS8kopraq16fsLIbovSfqtibkBnDzPe3TumUaG98DRrNia0ny9fkJGEb393Jjczx+tYZ+U9oUQNiJJvzXOHjBsHiR+BWWtN7y2h6uTmYnR/nyyNZ1Dx0vQWvPv1Yd5rH7ZxfiMIoaH+TA0xBtou16/ts4i0zgLIawiSb8to++GumqI/8Smp/3btUNxc3bgvo/i+N2yPbz8wyE+35nJY8v2cLy4imFhPvh5OBPi48qerJNU11pYue8Y6w7lkZxb0pDk4zOKGPPCat7bmGbT+M5VaVUt3yfm2DsMIUQLrFo5q1sLHAgRk2D7OzDuATA72uS0Pb1d+M/NI7nxna0c2ZnJQzOiOVFezSdbjSkahtevvjU01Ju4I4XMfXsLu48WNbx+ZLgP140K5a8rDlJaVcsXu7K4Z3KUTWI7H4u2pfPCioP8+JupRAd62DscIcQZJOlbY+J8WHQD7P0cht9ks9PG9vblrVtHUVJZy5zhIVTXWtifXcz+Y8UMCvYCICbUm//ty+FkRQ2vzh1GWA83ErOL+c/aFJ76ah+R/u7cEBvGwk1pZJ4oJ7SHm83ia86flifi7GDiySsHNrt/b1YxADvTCyXpC3ERkqRvjb6XQdAQ2PhPGDoPTLarFZsxIKjhdycHEx/eNYaMwgqcHcwA/HxoMInZxTx8SV/6BXkCxsVi7ugw/rfvGJOiAyiprGHhpjRWH8jl9gm9z3qPypo6CsqqCfZ2QSnVsP1oQTnvb07j/2b2w9u17TuY5NxSPth8BKVg9vBgBgd7n3VMYn2j8870E8wdHd6u70IIceFJnb41lIJJj0B+EiR9d0HfytPFsaGUDxDm68aCm0Y2JPxTXBzNXDMilABPZ6ICPIjyd+fHA8ebPeez3+xn4t9+YvRfVvP4sj1UVNdRW2fhocW7eX/TEZ5dnmhVbO+sT8XZwYSXiyN/X5l01v6yqlrSCoxpo3e20B1VCGFfkvStNfga8I2C1X+G8tbnzbGHmYOC2JpacNaArzqLZlViDiPCfZgY7cfSnRnc9cEOXvnhEAkZRYyP8uPL3Vms3Nd64+vx4kq+2p3FDbFhPDg9mvWH8tiU3HS20APHitHaaG9IySvjRFm1zT/nxeCpr/by9e4se4chxDmRpG8tkxl+9jKcOAIfzoayi2t65JkDg6ip02w4Y9rm3UdPUFhWzV0TI/nXvBG8esNwtqUV8MbaFGYPC+bDu8YwONiLp77a22qSXrgpjVqLhXsnR3Hr+INim3MAACAASURBVAhCfFx5+fumpf1T4wlOVTHtzujcpf3m1jMurqxh0fajF01vKSHaS5J+e/SZATcthoLD8PHVUHfxjJQdGe6Dj5sjP+5vWsXz44FcHEyKqf0DALh6RAiv3zSSGQMC+fOcITg5mPjHL4ZRUFbNou3NL+5SXFnDoq1HuTKmF+F+brg4mrljQm92HS0iJa+04bjE7GL83J24bFBPzCbV7iqe33+1l98siW/nJzfkFldiseGi8+kFZQz+40o2n3E3szfTmCJjb9ZJ8kqqbPZ+QnQUSfrt1WcGXP0fyNlr9Oa5SDiYTczoH8iapFxq6ywN21cfOM7YKF+8XE431F4Z04uFd4zG283YNrCXFxOj/Vi07Sh1Fk15dS0Pfba7YbGXRduOUlJVy6+m9mk4x5zhwZgUTao59mUXMzjEG1cnM4ODvdqV9Mura1m2M5Mvd2exNql9i8dvTsln3F9XM3/x7iaf/XysTcqjssbCZzsymmw/NUUGwPpDea2e42RFDcsTssktrrRJTELYgiT9czH4GugZA+tfvKhK+zMHBXGivIZd9f350wvKOJxbyiWNegi15JaxEWQVVbDmYC6vfH+IbxKymb94N5knylm4MY1J0f4MCTndWyfQy4WJ0f58tTsLi0VTVVvH4eMlDK5vhB4Z3oOEjJPUtJCEq2stXPPGJhbWV5NsTi6gutaCu5OZ577dT3Wtdcm7pLKGxz7fg6eLI9/uOcb/LYm3KvEv2naUa9/Y1GwVDsCW+ikyftifQ1mjuY/iM4qI9HfH38OZtW0k/YUb05j/2W7GvLCam9/d2tDeUmfRfLzlCF/tziQx+6SMphYdSpL+uVAKpj0JhamwZ4m9o2kwua8/jmbV0IvnxwNGiXnmwLaT/sxBQQR6OvPiqoMs3JTGzIGBlFfXcs0bm8ktqeKXU88e+HXtyBAyT1QQl36CQzml1Fo0Q+q7cY6N9KWipo7Xf0pGa83mlHxm/XM9Px00YlsSl8Huo0X8Z10K1bUWVh88joezAy/fMJzUvDI+3HzEqs/83Df7OXaygvfvHM2TVwzg2z3HeH1Ncpuv+35/DruOFrE55ey2GYtFszWtgOhADyprLPxQX2WmtSY+o4gRYT5M7RfAhsN5LV40AHYcKaRPgDsPzYhmU3IBX+zMBOC7vcd4+r+JPLIkgZ+9tpFXfzjUZrwnyqpJyy9r87iu5Iudmew62rnbhS5GViV9pdQspVSSUipZKfVEM/t/o5Tar5Tao5RarZSKsH2oF5n+V0KvYbDu71BR1PbxHcDTxZFxUX78eOA4FdV1fLo1nf5BnoT7tT1gy9FsYt6YcA4dL8Xfw5lX5g7nqSsHkldSxeBgLyZF+5/1mssH98TNycyCNcm8tT4FoKGkf9ngnlw3MpR/rT7MXR/s4Nb3tpN0vITfLk3gaEE5/159GH8PZ/JKqliZmMPqA7lM6efP5YODmN4/gL+tPMiS+gXkT1bUsD2tkISMIvZlnWTD4Tze35TGlf/awOc7M7l/Wh9Ghvfgl1P7cPngIN7bmEZxfam6qLy64fdTtNYNjc7L6hNxYwdyiikqr+H+qX0I9nZheUI2AMdOVpJXYkyRMa1/AEXlNU2qexqrqbOw+2gRk/sG8NvL+jMszIePt6ajtWbhxjQi/d354ZEp/HxYMK+vSW7xPKc8+eVe5ry+scldR1eWnFvCbz9PYN7bWxsKCsI22kz6SikzsAC4AhgE3KiUGnTGYbuBWK31UGAZ8KKtA73oKAWXvwDF2fDJdVBZbO+IAKNUn5pXxq8X7SI1v4xnfn7mn6plN48NJ9zXjb9eG4OXiyO3jIvg8VkD+Pt1Q5sM6jrFzcmBn8X0Yt2hPFbsPcbYSF/CfY0LjNmkeOn6odw2PoI1SXlM7x/A1w9MpKKmjjkLNpJbUsXrN40gzNeVv644QG5JFTMGBKGU4rUbRzAx2p/Hv9jLdf/ZTOzzP3DDW1uYs2ATV/17I7e+t51nv9mPUvDnq4fwyMx+DTE9NKMvJZW1fLwlnYzCci59dT2jn/+R+Z/t5tDxEgByS6rIL63Gy8WBlftyzroonKramRDtx8+HB7P+UB6FZdUNiXl4mA+T+/pjUrCuhfaH/dnFVNTUEdu7BwC3josgJa+MN9amEJ9RxJ0Te9M3yJO/XDOEnl4u/HZpPG+tS2HaS2t4bfXhJucqKK3ixwPHKa6s5YtdTS9SWmsqa7reOsrvbkjD2cFE30APfvnxTv4bL11kbcWakv4YIFlrnaq1rgYWA3MaH6C1XqO1Lq9/uhUItW2YF6nek+AXH8CxePj0eqgub/MlF9olAwMB+OlgLvdMimRiMyX0lgR5ubD+d9O5pL46SCnF/dP6NKnLP9Ozcwaz6v+msP+5WSz55XhMptMXB5NJ8ezswfzv4cm8fWssw8J8+P2VAzlRXsOUfgGMi/LjlrERHDtZiVIwvb6HkaeLI+/dHstt4yM4UVbN7eN78/6do1l4Ryxv3TqKpb8cz7rHpvHd/MncOi4CB/Ppf8ZDQryZMSCQdzekcvv726mutXDdqFDWHMzl15/uAk53LX14Zj+qai18t+dYk8+0JaWASH93enm7MmdYCLUWzUurDhKfUYST2cSAXp74uDkRG+HLin05zdbJ76hfAzk2wheAq4b2wsfNkZdWJeHp4sB1I43/Il4ujvz9+qGk5JXx1/8dpKiihnc2pFJefbpE/9/4bGotmhAfV97fdASLRbPxcD5X/XsDg55ZxdA/fc/BnHMvdFTXWigqP91dt7Km7rzOd77ySqr4cncW140K5bP7xjEirAcPL47n6a/32fwCV1lT12K7U1dlTdIPARp3Ycis39aSu4H/NbdDKXWfUipOKRWXl9d6I1inMfAquO49Y6GVbx62+Spb7RXaw41hod4M6OnJo5f3v+Dv5+bkQP+enrg4mpvdr5RiYC+vhovBreMi+Nu1Mfzt2hgAbogNw9nBxIj6WUVPcTSbeG7OEH56dBp/uGoQ0/sHMmNAEJcP7smYSF8i/NxbjOnX06M5UV5D5okK3rktlheuieGRS/txOLeUjMJy9mUVoxTMGx1GdKAHn25L5/DxEuosmto6C9vTChkX5QfAoGAvfjW1D59tz+CDTUcYFOzVMEXGnBHBJOeWsi/r7AQZd+QEYb6u9PR2AYwR1DfEhgFw45hw3J1Pz4AyuW8A7985mu/mT+Ld22Ipqazlv/HZDfuX7cxkaKg3v5vVn7T8Mv65+jD3fLSDsqo65o0xvr9//dj07qAlqXmlzHt7C7ct3E56QRnJuaX87LUNTPr7Gjan5FNaVcst727jin9taFcbQm5xZYsrwbXXx1vTqa61cPekSLxcHPnknrHcOzmSj7em8/Di3VafJ7+0ivs+iiOjsPnCWEZhOTP+sZbr39zSae6WbNHob83cO2ff10Oz76yUugWIBaY2t19r/TbwNkBsbGzX6bIw+GrIfwrWPA/Bw2H8r+0azkd3jcVsVi0mYntSSjFvzOk5eXq4O/H6TSMJ9HRu5VXtMyqiB09eMYABvbwYE2mUtGcMCOS5b/fz08Fc9mWfJMrfHXdnB+6c2JunvtrHpa+ux8lswtXJTElVLeP7+DWc7/FZ/amzWHhnQ1rD7KcAV8UE8+zy/XyxK5OY0NN3Q1pr4tILmdI3oElcd07sTVp+GXdPijwr5un9AxteO6CnJx9vSWfe6DAOHCth/7Finp09mCtjevHCigO8tvowkf7ufP6r8fh7OOPp4shrqw+zP7u4yRQeZ1q6I4On/7sPF0czFovm8n+ux6SMfydBXs7csXAHkf7uJOeVorVxt3j3pEhyiyv5/Vd7+eXUPozu7XvWeWvqLFy9YBPRQZ58dNcYK/9KzausqeOTrenMHBhEnwBjwj4nBxNP/WwQzg5mXl+TTHpBWasX/VMWrEnm+/3HGRHeg/un9WmyL+dkJTe/u43iylqOFRfx2LI9vDZveLPVmBeaxaJJzC5u8m+oJTe+s/W838+apJ8JhDV6Hgpkn3mQUmom8BQwVWvd/UatTP6tUc2z6inY9yX0ngixd0OPjm/TPtX/vrO4dFDbvYva65dTm/4n7+3vTpS/Oz8dzOXw8RJG118Mbh4bwdhIX+IzTnI4t4TyqjrMJsXM+moyMC5Uv79yICPDezRcRMD4nmcOCuSbhGye+tlAHOurmY4UlJNfWk3sGQmyl7cr79wW22rcSiluHR/BU1/tY8mODP63LwdHs2L2sGAczSb+b2Y/3t+Uxnu3j8a//s7o7kmRvL8pjZdWHSQm1IfP4zJ4fNYArh5x+oa8qraOPy5PZGioNwtuGkmd1vzxv4mUVdfyj18Mw9XRzN0fxpGQUcSCm0byj++TWJtkJP0lOzL48UAuG5PzefOWUUzrH9gk5p8O5pJ9spLsk5UkZBQxLMyHl1YdJC2/jNfmjWhS/daWL3ZlUlhWzb2Tz74w3jo+gv+sS2HRtqNNZnktLKvmy12ZFFfU4OpkXMhPlFfz6TajI8COI4Xcz+l/D1pr7v0ojsKyaj65ZyybU/J5cWUSpZU1+Hs4MyqiR0PB5Eh+GZtS8rlpTPgFuyB8HZ/Fb5Ym8O1Dk1qtSj1aUM7W1POfAsaapL8D6KuUigSygHlAk/mFlVIjgLeAWVrr9o2s6SpMJrjmLdj8GqSthy1vwNY3Ydz9MOUxYxUuYVfTBwTy0ZYj1NSd7loKEB3oSXSgZ8svxEjGV8T0Omv7NSNCWbE3h/WH8hraQk7NSTS6vhG3va4eHsLfVhzkiS/34mQ28eD0vvRwdwKMqqEbxzSdvdTb1dGYZmP1YdYk5dHL24VHP0+gh7sTU/sZdxvb0wqpqKnj/ml9CPQyqpzePuMC9Nm94ygoq6KXtys70wv5cHM6pVW1fLk7i2Gh3tTUGcny9ZtGcvngnqdft/0ogZ7OVNbU8cbaZOaODmPBGqM3V5hvEk9ecfY03IVl1SzcmMa9k6MaCikWi+a9DWkMDfVucnE9JcjLhcsGBbE0LoNHLu2Hi6OZOovmVx/vZPuR08nwh/05hPu6obVmcl9/4o4UYrHohirGlLxS9mad5NnZgxke5sOwUG/yS6pZlZjD3qyTfL4zE1cnM9P6B3L7+9tJLygnJsSboaE+Z8XUlpLKGh76bDduTmbeuHlUs8esqx/vsTE5v9Wk/82es8ra56TNS7DWuhZ4EFgFHACWaq0TlVLPKaVm1x/2EuABfK6UildKLbdJdJ2NswdM/z3ctRIejjcGcW36J7x3KRSk2Du6bm/GgEBq6oxaxcEhLVeDtMfUfgH4ujvx0qoklsZl8Lf/HeSPyxOJ8ndvqJ5oL3dnB167cQR/vTaGHU/N5OGZfdt8zX1TonhkZj9WzJ/Mqkem0DfIk/s/2cmBY0Z7w5qDeTg5mBgf1XLDvpODiV7eroBxgayus7BgTTJp+WXcPC6Cz+4bx+Bgbx5ctIvV9WNBMk+Us+5QHvPGhHPHhN6sSjzOb5cm0D/Ik7mxYby1LvWsqUEA3liTzOtrkpm/eHfDWIfVB3NJzS/jnslRLZaqbx0XwYnyGlbsNRrfF25MY/uRQl68biipL1zJf24eSWJ2MV/HZ3NDbBhXDw+huLKWpPqeWwA/7DfKpafuMJVSPPPzQWx6YgZbnryE0b178MQXe7n3oziyTlRgNilW7G3/anBF5dXc8u421iblsWJvDqmNpiw5xRjDYvQWO1VYyC+tYvbrG8/qxvtNQjajIs6tINGYVfddWusVWut+Wus+Wuu/1G97Rmu9vP73mVrrIK318Pqf2a2fsRvwDoVr34Jbv4KSY/DOdDj8g72j6tZG9/bFo74Btbm1AM6Fk4OJZ64aREllLb9btoc316Vw3cgQvnxgQpOeTO01fUAgN44Jt7qqzt3ZgYdn9mVQsBdeLo58eOdoXBzNvLjyIABrD+UyLsoPVyfr2nliI4zv6u31qbg4mrhiSE+8XR358K4xDOzlxf2f7OKV75MaSvRzR4dxx8RIXB3NlFTW8vINw3h2zmCGhHjx8OLdrGnUtbWksobFOzII83Vl3aE8Xv4+ibT8Mt5cl0KIjytXDunZUliM7+NHVIA7L6w4wO+WJfDS90lcOiiIX8SGYjIZd2OL7h3LFUN68vAlfRvuGHY0uhNYfeA4g4O9CPZxPev8jmYTC24aibuzA9vTCnn6qkFMjPbnf/uOWd2IeuxkBS9/n8Slr67nQE4Jf7s2BrNJsSQu46xjD+eWkldShb+HEzuOFFJVW8dXu7LYk3mSNxoNMjx0vISDOSXMHhZsVQytkRG5F1qfGXDfWvAJh09/AetfsnsPn+7KycHEJQMD6RfkYdWiMda6ekQIGx+fzrcPTeK7+ZN48fph+Lg52ez85yLQy4U7J/RmTVIeqxJzSM0rY1q/gLZfWM/JwcSkaH/qLJrLBvXEs37uJm9XRz66awwTo/3495pkPtt+lGn9AgjxccXX3YlX5w7j9ZtGMiTEGxdHM+/dPpoIP3fu+TCuYXDakh0ZlFbVsuCmkcwbHcYba1OY/o+17Ew/wX1TolptA1BK8Y9fDGNYqA//25uDt6sjf702psmdwagIX/5zyygCvVwI7eFKL28XtqcZSb+gtIpdR080VMW19N19dNcYnr96CLeNj+DKIT1JLygnMbvtbqz7s4u5/NX1vL4mmSHBXnx27zjmjQnnkgGBfLEzs6F7bGK20W34VOn+gWnRVNYYA/pOjcX48cBxsosqAFgen41JGfNmnS9ZOasj9OgNd30P38yHn56H7Hi45k1wbr0eWdjeC9fEUGXlvD7toZRqtT7WHm4b35u31qfy6OcJAEzrb33SB5gxMJCViTlcO7JpD20fNyfev3MMx4sr+elgLhMa9XSaNaRpUgrycmHpr8bz0KJdPP31PtYfymN/djFjevsyNNSH/j09GRbmg6PZRKS/OyPD2643Hxneg/fuGE1tnYVai261l5pSitG9fdmWVoDWmjVJeVg0XNrG1CSDgr0aekJdNrgnT329j//tO0akvzvb0gqY2i8Q8xl3cql5pdy2cBvuzg58/euJRDWq3rtxTDjf7z/Ov386zLKdmRwvrmTZ/RPYlFxAuK8b140K5fnv9vPuhjQO5pTwq6l9eGu90Wh996RIvtqdxcRofwJs0MtNkn5HcXKDa9+B4BHw/dPwziUwbxH4R9s7sm7F3dkBd9v1Dr2oebs5cvO4cN5al0qEnxuR/m13c2zs2hEh9PJ2aXYKDjAS+pmNys3xcHbg3dtHs3BjGi99n0R1raVhpLizg9mqczTHwWzCwYraqtGRvixPyCYlr5Qf9ucQ5OXMkHa06fi6OzE+yo8lOzJZsiOT/NIqfnNpP+ZfYrS11Fk0X+3O4u8rD6I1fHz32CYJH2BKvwB6ernw75+SCfFxrR+FnUB+aRVXDe2Ft6sjMSHe/HjgOE5mE7+aGkVybgmLdxxlZWIOeaVVvPSLoe36floi1TsdSSmjD/9tX0N5PnxwpTFpW3OydsGKx6C2+/V+FbZz96RIXBxNXFI/xUV7OJhNTO4bYJOuimaT4t4pUayYP5k/Xz2kzZK2LY2tr9ef+cp6ViUeb5juoz1mDwsmv7SKKH93ZgwI5F+rDzfMBfXzf2/k0c8TCPZ24dN7xxIdeHYDvtmkeOzy/lw9PJhvHprEyzcM50hBGSWVtUzoY1xUx9c/zhwUiI+bE7eO701+aTXHT1by0V1jGo47X8pe07rGxsbquLg4u7z3RSH3ILx/hdHjZ+4nRj2/Z0/jp6YS/jMBClNgxh+MLp9CnKP0gjICPJ1xc+qeN/Zaa5btzCS/tBqTgjnDQxpGSrfnHMm5pUQHelBcWcsV/1xPjUVzoqwaX3cn/nDVIK6K6dWuxvsXVhzgw81H2PTEDPw9nNmWWsDct7fywZ2jmdY/0OjCujGNidH+TQbdKaV2aq1bH/DRCkn69pS1y1h6sbq+O5mjmzGXT9ZOY/bOoCFGV88HtxsNwUKIi8LmlHxuX7idWUN68ec5g8+p4V5rTX5pdZN6+qMF5W3OiitJv7PLOwQZ28DFGzb8w1iRS5mNPv6XPAMLxhg9gOZ+YlQPCSEuCuXVtXa5ezrfpC91+vYW0A9G3gqDZsMdKyD6UnDzNaZt9gmDqb+Dg9/Cm5Nhz+dQXt/fuKIIjmyCqrMHfAghLrzOWl3WOaPuqpw94OalUFsNDvW3ixMeBo8g2PgqfHmPsc0z2BjwhQbvcJj9GvSZfvo8Whs/JrmmCyGakqR/MXJoVD9oMsHwm2DoPDi62ZjCOXc/+PUFvz6w9m/w8dXQ/2cw9j6jumjTP8G/H9z8OZg71+RrQogLS+r0O7uaSiPJb38byo05PAgaAsf3wZj74MqXTh+7f7mxpm9JDlhqIHIKhE8wXldxAmKuB69WhnlrDQmLjUFlA6+6sJ9LCNEsacgVhpoKOPid0eUzYiJ8/wfY8jpMmG8MCDuwHBK/MqqD/PqApRaObjWS/ykOrjD2l+DgYnQXDegP/WYZ1UvlBca00SmrjWNnPG1MJy2Ny0J0KEn6onl1tbDkFjhUv4iZyRGmPQETHz5d5VNVAscTjaSuLbDmL7DvC0AZJf7iM9YldXSDmc9C5g7Yu9RYHH7AzyB8PPSINC4AhalwMtO48Jgb1R6mbTAuQlWlYDKDyaHRowMEDYahN4BvVId8PUJ0VpL0Rcu0NqptSnLA1af1qptTSo6Dixc4uhq/p6yG6jIj4feeZCwKY7HA+hdh+zvGyGIAZy9w8oCS+jm/vUJh2DzjYnIsHlJ+As9eRlK31IKlznjUdUbDdf4hQBttFb5REDjAuJj4RkFpLlSXGtVK7oHgF220deQeMO5uwsYaFxlpuL741NVCVbHRI03YhCR9YT9aQ95BY5zBsT1QWWQkand/iFtoLCajzMbFZvTdMPZXxsWkOSezYO/nxsC0wjTjvJYW1lx1DwCfCMhq9O/HJ9w4/6g7wOmMOWbyDxu9n/IPG+MhnNwAZVwIe0822kBKjxsXF11n3Hn49QH//vXHtqAs34j3eKIR09C5TRvh62qM9yxIhqJ0o7ttdWl9/OEw8Odnx5qxw6ii8wmj09Eavv0/4/er/mk8Lppr/Pv49Xbw7LipF7oySfri4lVVatwhnEsJvKbCGLFcnA0egUYpv6oETmYYF5O8gzBwtnE3kb4Fdn4A6RvB1de4G6mpBGUyqrJy9hjtFCGjjHPUGNPVUpIDVSdbj8PFx3j/oTfAuAeMO5SD3xnVW6lrjTuZU7zDjfEWFSeMkdTH4qG28vR+kwM4up9+T58ImP1v6DXMqBZb93c4tNI4ZtYLMPL2s9tMtIayPKPLbkGy8dlz94NrD+NiETgQgmKMC5qDs3HHZe6gTnqJX8Hndxi/X/5X44L5zcPG86Fz4dq3OyaOjlRXC0nfGYWHlu5mLBbjrtbByfj7Ze82CkhR08+pTUySvhCnHN0K296sv9i4GP/Baiqg11AY92vwOGNq4bpaOJYABYeNuxGPnkY7Q119dVNeklH6zz8EaevAzc+o6qqtNErqMb8wBtMFDoTMOFj7gnHH4xFoLKITMspoRPfva7R5uHgb/8lrKiFjK3z7SNMJ95w8YdLDRvtH2joIGAARE4wqrZJjxrE5e6Cy0YXK0d1oD6kuNe6WzryIObpDyEijC69nL+McqWuNc7j7GVVyKOOiETYaAgcbFzIHZ2MkuIuVs1GWFxqjx71Djfc5/D2YnSF0FISOhg0vw+3fQuRk6/+ex/YY1YvpW4x4IiYYMQX0b/u1Whuj249sMDoj+PVp/riaCijKgIpCo7PCqcGPPuHGnVryD8a/A58wo6rRN8qYKt3Fx6ja/PY3xsU9YCDcvtz4259iqTN6y615wbiTDB4JNeXG3xCMi/qV/zh9d5i1C3Z9CCGxRu841+ZXyZKkL0RHOLoVNv/bSGhDbzASWXOlNK2tL71Vl8Puj41SoHuAUfLzCDBKhrs/MrrYZu4w7k5OVQn1jDEuMl7B4B1mVE2dKslrbdwJ5R4wLgLV5Ubiy9wBJ9KMOxDXHhA1zRjgV55vXMTAuKPK2WPEcorZGaJnGknWO8S4gDg4Gz9mJyOBVRYbF6SUn4wxJL9cZyT+t6ZA+Ql4YDO4+cMbY41jXbyMROsVbCTQyKnQ91LwCjG+t/JC405u+9uQvsmIw7+fcaE8aSx0TtAQo10nZ49xzpCR0Gu4kXBNDkZ35SObIO+AcbzJAWLvNu42esYYz0uPw873jUJCZSt3ew4uxucvzjbusM7kHgBjfgkbXzH+Hv1nQeZOKM40qv+qS43Yek8yqrksdca4m+Iso8oxeKQxsLKiyIhHmY1qTZOj8b0MvtZ4f2dPowBSkIwaeYskfSG6LIvFaGewxSC7mgojWZtamIS+uty4aJgcjAST+JVRYj+Z0fRi0ByPIJj0CIy733hekmNcrPzr1/c9shE2vVZf7eRiJL3cg0ZyBKO7sJvf6efeYUYbzdC5p+/QijIgaYXRw6wkx7iDc/Yy7rLyk07H4uQJwcNh8NVGtcvWN2DXR8YdjNnJeDz1eQZcBYPmGFUzrr5GDLrOeC9dZ7RRnWqHqiw2Lp4n0o3G6bpqGHS18dojG2HRPKirMi4svn2M7eHjjWrI5qo49yw1qvQK04yYRt9tzLdVkAz7vjR+Ss5eDF09WyxJXwhxAVnqjItATbmR6GqrjKoPR1ejBOoRZFSntdepjgCp64wLS1mecZEIH2/0yGrPha6uxrhLqK0w2lbOTLIlOXB0i1GFYnIw7gqiphl3TbZSXW5cUB3auUpPXY1xR3BmdY7FYtT/l2QbFxx3f/CLRvlHS9IXQojuQmbZFEIIYTVJ+kII0Y1I0hdCiG5Ekr4QQnQjkvSFEKIbkaQvhBDdiCR9IYToRiTpCyFEN2K3wVlKqRIgqc0D7c8fyLd3EFaQOG2nM8QIEqetdZY4+2utPc/1xfZcGD3pYr6AngAABTtJREFUfEaVdRSlVJzEaTudIc7OECNInLbWmeI8n9dL9Y4QQnQjkvSFEKIbsWfS7yzL6EicttUZ4uwMMYLEaWvdIk67NeQKIYToeFK9I4QQ3YgkfSGE6EbskvSVUrOUUklKqWSl1BP2iOFMSqkwpdQapdQBpVSiUurh+u2+SqkflFKH6x+bX624gymlzEqp3Uqpb+ufRyqlttXHuUQp5XQRxOijlFqmlDpY/72Ovxi/T6XUI/V/831Kqc+UUi4Xw/eplFqolMpVSu1rtK3Z708ZXqv/P7VHKTXSznG+VP9336OU+kop5dNo35P1cSYppS63Z5yN9j2qlNJKKf/65xfV91m//aH67yxRKfVio+3t+z611h36A5iBFCAKcAISgEEdHUczcfUCRtb/7gkcAgYBLwJP1G9/Avi7vWOtj+U3wCLg2/rnS/+/nfsJtaqK4jj+WWRKGmEm1isDNTRoUkaB9o8y+6OIETQwhIxq0qxJhTwIGgYRTiKDIqKkKBMTIYQsGmopmdIfMrR8pqmDDGqitBqcffP6ulK9gefA3V943HPW3oMfv3fWumevs8/FqnK8Hk92QOObeKIcT8b0rvmJq3AAF/X5+GgX/MQduBH7+mID/cNyfITAIuxoWee9mFSOX+jTeV3J+SmYW2rBBW3pLPGrsQ0/YmZH/bwLH2NKOZ81UT/P60VcRC7Gtr7ztVh7vnX8B50f4h7NW8MjJTaieamsbW2zsR1LsLVcmCf6kuwsj1vSeEkppjEu3ik/S9E/hBmalxW34r6u+Ik545J/oH94FQ8PmteGznFjD2JDOT4r30uxXdymTmzE9TjYV/Q75afmJmTpgHn/28822ju9JOsxVmKdISLmYCF24PLMPALlc1Z7yv5mHZ7Bn+X8MvyamafLeRc8nYfjeKO0oV6LiGk65mdmHsaL+AlHcBK7dM/PHufyr8t59ZjmrpmO6YyIlTicmXvGDXVKJxbg9tJy/Cwibi7x/62zjaIfA2Kd2TcaERfjAzyVmb+1rWc8EbECxzJzV394wNS2PZ2kWaK+kpkL8bumHdEpSk/8Ac3S+EpMw7IBU9v289/o4jUgIkZxGht6oQHTWtEZEVMxiucGDQ+ItennJFyqaTU9jfciIkxAZxtFf0zTQ+sxGz+3oOMfRMSFmoK/ITM3lfAvETFSxkdwrC19hVuxMiIO4l1Ni2cdpkdE77eUuuDpGMYyc0c536j5Euian0txIDOPZ+YpbMItuudnj3P517m8iog1WIHVWXoPuqXzGs2X/Z6ST7OxOyKu0C2dNHo2ZcNOzSp/pgnobKPof475ZXfEZKzClhZ0nEX51nwd32TmS31DW7CmHK/R9PpbIzPXZubszJyj8e6TzFyNT/FQmdYFnUdxKCKuLaG78bWO+alp6yyKiKnlGujp7JSffZzLvy14pOw6WYSTvTZQG0TE/XgWKzPzj76hLVgVEVMiYi7mY2cbGjNzb2bOysw5JZ/GNJs5juqYn9isucETEQs0GyNOmIif5+vBxLiHD8s1u2N+wGgbGgZouk2zLPoKX5a/5Zp++XZ8Xz5ntK21T/OdzuzemVf+2fvxvvKUv2V9N+CL4ulmzfK0c37ieXyLfXhLsxOidT/xjuY5wylNQXr8XP5plvkvl5zai5ta1rlf02vu5dL6vvmjRed3WNamznHjB515kNs1Pyfj7XKN7saSifpZf4ahUqlUhoj6Rm6lUqkMEbXoVyqVyhBRi36lUqkMEbXoVyqVyhBRi36lUqkMEbXoVyqVyhBRi36lUqkMEX8BuZ1jEUGS8iIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_loss = pd.DataFrame(model.history.history)\n",
    "model_loss.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       249\n",
      "           1       0.97      0.91      0.94       124\n",
      "\n",
      "    accuracy                           0.96       373\n",
      "   macro avg       0.96      0.95      0.95       373\n",
      "weighted avg       0.96      0.96      0.96       373\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[245   4]\n",
      " [ 11 113]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
